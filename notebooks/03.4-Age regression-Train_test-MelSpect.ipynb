{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=6\n",
    "\n",
    "from numpy import empty\n",
    "from numpy import load\n",
    "#import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "from src.training_setup import kfold_cv, train_holdout\n",
    "\n",
    "# Set CPU as available physical device\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy.fftpack\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '.')\n",
    "my_seed = 19951008\n",
    "import random\n",
    "random.seed(my_seed)\n",
    "from numpy.random import seed\n",
    "seed(my_seed)\n",
    "from tensorflow import random\n",
    "random.set_seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 s, sys: 18.9 s, total: 1min 2s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/numpy_train_obj_unbalanced.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X, y, X_spk_labels, X_spk_labels_aug, X_aug, y_aug = vectors\n",
    "X_spk_labels_aug.shape\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n",
    "\n",
    "X_mel = empty(X.shape, dtype='object')\n",
    "for i in range(X.shape[0]):\n",
    "    X_mel[i] = scipy.fftpack.idct(X[i])\n",
    "X_aug_mel = empty(X_aug.shape, dtype='object')\n",
    "for i in range(X_aug.shape[0]):\n",
    "    X_aug_mel[i] = scipy.fftpack.idct(X_aug[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv('age-train.txt')\n",
    "test_metadata = pd.read_csv('age-test.txt')\n",
    "title_only_metadata = pd.read_csv('age-title_only.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 s, sys: 1.88 s, total: 7.63 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/test_data.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X_test, y_test, X_spk_labels_test = vectors\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n",
    "\n",
    "\n",
    "X_test_mel = empty(X.shape, dtype='object')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_mel[i] = scipy.fftpack.idct(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_recordings_index(spk_labels):\n",
    "    print('get_correct_recordings_index >>>')\n",
    "    spk_labels_dict = {i:spk_labels.count(i) for i in set(spk_labels)}\n",
    "    least_freq_spk = min(list(spk_labels_dict.values()))\n",
    "    print(least_freq_spk)\n",
    "    speaker_indexes = []\n",
    "    frequency_spk_labels_dict = {}\n",
    "    for x in set(spk_labels):\n",
    "        frequency_spk_labels_dict[x] = 0\n",
    "    for index, spk_id in enumerate(spk_labels):\n",
    "        frequency_spk_labels_dict[spk_id] += 1\n",
    "        if frequency_spk_labels_dict[spk_id] > least_freq_spk:\n",
    "            next\n",
    "        else:\n",
    "            speaker_indexes.append(index)\n",
    "    print('get_correct_recordings_index <<<')\n",
    "    return speaker_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test set, currently, there are all labeled pairs person-yt videos, however we need to balance them so that each speaker has the same weight. The first step is to identify the ids of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_correct_recordings_index >>>\n",
      "1\n",
      "get_correct_recordings_index <<<\n",
      "CPU times: user 333 ms, sys: 370 Âµs, total: 333 ms\n",
      "Wall time: 333 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_spk_video_labels_test=X_spk_labels_test\n",
    "X_spk_labels_test = [''.join(x.split('-')[1:]) for x in X_spk_video_labels_test]\n",
    "test_ids_balanced = get_correct_recordings_index(X_spk_labels_test)\n",
    "len(test_ids_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we'll have 958 test records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[test_ids_balanced]\n",
    "y_test = y_test[test_ids_balanced]\n",
    "X_test_mel = X_test_mel[test_ids_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958,), (958,), (958,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_test_mel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train\n",
    "## CNN 1D : Multi input - Multi output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse_plus_cross']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhechmik\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/khaled/miniconda3/envs/tf/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mel_spect_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/o3a1g77y\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/o3a1g77y</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_223051-o3a1g77y</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 50, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mel_spect_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse_plus_cross', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210328-223050', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 15, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 8, 'multi_output': True, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 5, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "16949612\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 200, 30)      2730        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 200, 30)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 30)      120         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 200, 30)      2730        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 200, 30)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 30)      120         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 30)      2730        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 30)      120         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 200, 30)      0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 200, 30)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 30)      120         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 100, 30)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 100, 60)      5460        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 100, 60)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 60)      240         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 100, 60)      10860       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 60)      240         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 100, 60)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 60)      240         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 50, 120)      21720       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 50, 120)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 120)      480         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 50, 120)      43320       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 120)      480         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 50, 120)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 120)      480         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 120)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 120)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          30976       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 8)            1032        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 158,759\n",
      "Trainable params: 156,671\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n",
      "multioutput_y_preparation >>>\n",
      "Train label encoder output: (92955,)\n",
      "Test label encoder output: (958,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khaled/miniconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 190s 249ms/step - loss: 86.2858 - regression_loss: 649.4074 - classifier_loss: 2.1345 - regression_mae: 19.4138 - classifier_accuracy: 0.2255 - val_loss: 36.1824 - val_regression_loss: 176.3556 - val_classifier_loss: 1.8547 - val_regression_mae: 11.0379 - val_classifier_accuracy: 0.3027 837.3425 - classifier_loss: 2.2066 - regression_mae - ETA: 1:02 - loss: 102.0814 - regression_loss: 801.5216 - classifier_loss: 2.1929 - regression_mae: 21.9172 - classifier_accura - ETA: 59s - loss: 101.2035 - regression_l - ETA: 39s - loss: 95.0512 - regression_loss: 733.81 - ETA: 18s - loss:\n",
      "17143576\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 175s 241ms/step - loss: 36.2209 - regression_loss: 192.3002 - classifier_loss: 1.6991 - regression_mae: 11.3433 - classifier_accuracy: 0.3337 - val_loss: 34.5222 - val_regression_loss: 172.2102 - val_classifier_loss: 1.7301 - val_regression_mae: 10.5885 - val_classifier_accuracy: 0.2860\n",
      "17150676\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 171s 236ms/step - loss: 34.6549 - regression_loss: 180.4009 - classifier_loss: 1.6615 - regression_mae: 10.9258 - classifier_accuracy: 0.3504 - val_loss: 34.8942 - val_regression_loss: 173.9752 - val_classifier_loss: 1.7497 - val_regression_mae: 10.6675 - val_classifier_accuracy: 0.2996\n",
      "17150676\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 175s 241ms/step - loss: 34.1246 - regression_loss: 176.1343 - classifier_loss: 1.6511 - regression_mae: 10.7678 - classifier_accuracy: 0.3536 - val_loss: 35.7199 - val_regression_loss: 184.6546 - val_classifier_loss: 1.7254 - val_regression_mae: 10.5698 - val_classifier_accuracy: 0.3424\n",
      "17150676\n",
      "Epoch 5/300\n",
      "727/727 [==============================] - 177s 243ms/step - loss: 33.3937 - regression_loss: 169.8850 - classifier_loss: 1.6405 - regression_mae: 10.5428 - classifier_accuracy: 0.3652 - val_loss: 39.2599 - val_regression_loss: 206.8944 - val_classifier_loss: 1.8570 - val_regression_mae: 12.0517 - val_classifier_accuracy: 0.2610\n",
      "17150676\n",
      "Epoch 6/300\n",
      "727/727 [==============================] - 176s 242ms/step - loss: 32.8405 - regression_loss: 165.3124 - classifier_loss: 1.6309 - regression_mae: 10.3821 - classifier_accuracy: 0.3694 - val_loss: 40.6395 - val_regression_loss: 212.2241 - val_classifier_loss: 1.9417 - val_regression_mae: 12.2159 - val_classifier_accuracy: 0.2537\n",
      "17150676\n",
      "Epoch 7/300\n",
      "727/727 [==============================] - 179s 246ms/step - loss: 32.3062 - regression_loss: 161.4380 - classifier_loss: 1.6162 - regression_mae: 10.2326 - classifier_accuracy: 0.3750 - val_loss: 36.9705 - val_regression_loss: 193.5895 - val_classifier_loss: 1.7612 - val_regression_mae: 11.1670 - val_classifier_accuracy: 0.3142\n",
      "17152424\n",
      "Epoch 8/300\n",
      "727/727 [==============================] - 181s 248ms/step - loss: 31.9071 - regression_loss: 158.1528 - classifier_loss: 1.6092 - regression_mae: 10.1143 - classifier_accuracy: 0.3789 - val_loss: 36.0611 - val_regression_loss: 188.7022 - val_classifier_loss: 1.7191 - val_regression_mae: 10.6519 - val_classifier_accuracy: 0.3340\n",
      "17155932\n",
      "Epoch 9/300\n",
      "727/727 [==============================] - 178s 245ms/step - loss: 31.4926 - regression_loss: 155.0236 - classifier_loss: 1.5990 - regression_mae: 9.9925 - classifier_accuracy: 0.3816 - val_loss: 34.1062 - val_regression_loss: 167.8893 - val_classifier_loss: 1.7317 - val_regression_mae: 10.4093 - val_classifier_accuracy: 0.3173\n",
      "17155932\n",
      "Epoch 10/300\n",
      "727/727 [==============================] - 180s 247ms/step - loss: 31.2138 - regression_loss: 152.9961 - classifier_loss: 1.5914 - regression_mae: 9.9340 - classifier_accuracy: 0.3862 - val_loss: 34.1504 - val_regression_loss: 167.9031 - val_classifier_loss: 1.7360 - val_regression_mae: 10.6966 - val_classifier_accuracy: 0.3090\n",
      "17155932\n",
      "Epoch 11/300\n",
      "727/727 [==============================] - 175s 240ms/step - loss: 30.9026 - regression_loss: 150.6842 - classifier_loss: 1.5834 - regression_mae: 9.8615 - classifier_accuracy: 0.3910 - val_loss: 43.2564 - val_regression_loss: 232.1804 - val_classifier_loss: 2.0038 - val_regression_mae: 12.6048 - val_classifier_accuracy: 0.2516\n",
      "17155932\n",
      "Epoch 12/300\n",
      "727/727 [==============================] - 183s 252ms/step - loss: 30.6786 - regression_loss: 148.7105 - classifier_loss: 1.5808 - regression_mae: 9.7737 - classifier_accuracy: 0.3906 - val_loss: 37.5880 - val_regression_loss: 197.3222 - val_classifier_loss: 1.7856 - val_regression_mae: 10.8284 - val_classifier_accuracy: 0.3445\n",
      "17155932\n",
      "Epoch 13/300\n",
      "727/727 [==============================] - 182s 250ms/step - loss: 30.2902 - regression_loss: 145.7718 - classifier_loss: 1.5713 - regression_mae: 9.6769 - classifier_accuracy: 0.3967 - val_loss: 41.1055 - val_regression_loss: 216.0947 - val_classifier_loss: 1.9496 - val_regression_mae: 12.1251 - val_classifier_accuracy: 0.2724\n",
      "17155932\n",
      "Epoch 14/300\n",
      "727/727 [==============================] - 183s 251ms/step - loss: 30.0447 - regression_loss: 144.1101 - classifier_loss: 1.5634 - regression_mae: 9.5944 - classifier_accuracy: 0.3978 - val_loss: 38.2147 - val_regression_loss: 197.0331 - val_classifier_loss: 1.8511 - val_regression_mae: 11.6920 - val_classifier_accuracy: 0.2985\n",
      "17155932\n",
      "Epoch 15/300\n",
      "727/727 [==============================] - 188s 259ms/step - loss: 29.6120 - regression_loss: 140.6728 - classifier_loss: 1.5545 - regression_mae: 9.4690 - classifier_accuracy: 0.4037 - val_loss: 33.9742 - val_regression_loss: 170.2437 - val_classifier_loss: 1.6950 - val_regression_mae: 10.2456 - val_classifier_accuracy: 0.3518\n",
      "17155932\n",
      "Epoch 16/300\n",
      "727/727 [==============================] - 182s 251ms/step - loss: 29.3775 - regression_loss: 138.6021 - classifier_loss: 1.5517 - regression_mae: 9.4137 - classifier_accuracy: 0.4022 - val_loss: 34.0546 - val_regression_loss: 166.3391 - val_classifier_loss: 1.7421 - val_regression_mae: 10.4541 - val_classifier_accuracy: 0.3142\n",
      "17155932\n",
      "Epoch 17/300\n",
      "727/727 [==============================] - 197s 271ms/step - loss: 29.2376 - regression_loss: 137.7568 - classifier_loss: 1.5462 - regression_mae: 9.3889 - classifier_accuracy: 0.4056 - val_loss: 34.3249 - val_regression_loss: 169.0188 - val_classifier_loss: 1.7423 - val_regression_mae: 10.3692 - val_classifier_accuracy: 0.3434\n",
      "17155932\n",
      "Epoch 18/300\n",
      "727/727 [==============================] - 189s 260ms/step - loss: 29.2418 - regression_loss: 137.2027 - classifier_loss: 1.5521 - regression_mae: 9.3458 - classifier_accuracy: 0.4028 - val_loss: 36.1841 - val_regression_loss: 176.9480 - val_classifier_loss: 1.8489 - val_regression_mae: 10.9140 - val_classifier_accuracy: 0.3132\n",
      "17155932\n",
      "Epoch 19/300\n",
      "727/727 [==============================] - 170s 234ms/step - loss: 28.9155 - regression_loss: 134.9283 - classifier_loss: 1.5423 - regression_mae: 9.2683 - classifier_accuracy: 0.4040 - val_loss: 35.0946 - val_regression_loss: 171.5864 - val_classifier_loss: 1.7936 - val_regression_mae: 10.8385 - val_classifier_accuracy: 0.3006\n",
      "17155932\n",
      "Epoch 20/300\n",
      "727/727 [==============================] - 212s 291ms/step - loss: 28.5122 - regression_loss: 132.2424 - classifier_loss: 1.5288 - regression_mae: 9.1612 - classifier_accuracy: 0.4126 - val_loss: 34.2794 - val_regression_loss: 172.5228 - val_classifier_loss: 1.7027 - val_regression_mae: 10.2814 - val_classifier_accuracy: 0.3507\n",
      "17155932\n",
      "Epoch 21/300\n",
      "727/727 [==============================] - 222s 305ms/step - loss: 28.3845 - regression_loss: 131.1521 - classifier_loss: 1.5269 - regression_mae: 9.1441 - classifier_accuracy: 0.4124 - val_loss: 33.0640 - val_regression_loss: 163.0863 - val_classifier_loss: 1.6755 - val_regression_mae: 10.2380 - val_classifier_accuracy: 0.3518\n",
      "17155932\n",
      "Epoch 22/300\n",
      "727/727 [==============================] - 202s 277ms/step - loss: 28.3842 - regression_loss: 131.4406 - classifier_loss: 1.5240 - regression_mae: 9.1303 - classifier_accuracy: 0.4151 - val_loss: 35.3981 - val_regression_loss: 171.8482 - val_classifier_loss: 1.8213 - val_regression_mae: 10.8452 - val_classifier_accuracy: 0.2975\n",
      "17155932\n",
      "Epoch 23/300\n",
      "727/727 [==============================] - 202s 277ms/step - loss: 28.2028 - regression_loss: 130.0033 - classifier_loss: 1.5202 - regression_mae: 9.0717 - classifier_accuracy: 0.4165 - val_loss: 36.4013 - val_regression_loss: 181.8180 - val_classifier_loss: 1.8220 - val_regression_mae: 10.9787 - val_classifier_accuracy: 0.2881\n",
      "17155932\n",
      "Epoch 24/300\n",
      "727/727 [==============================] - 203s 279ms/step - loss: 27.8535 - regression_loss: 127.2108 - classifier_loss: 1.5132 - regression_mae: 8.9648 - classifier_accuracy: 0.4161 - val_loss: 33.4246 - val_regression_loss: 165.5307 - val_classifier_loss: 1.6872 - val_regression_mae: 10.0094 - val_classifier_accuracy: 0.3633\n",
      "17155932\n",
      "Epoch 25/300\n",
      "727/727 [==============================] - 199s 274ms/step - loss: 27.9065 - regression_loss: 127.5886 - classifier_loss: 1.5148 - regression_mae: 8.9901 - classifier_accuracy: 0.4194 - val_loss: 39.4417 - val_regression_loss: 202.6791 - val_classifier_loss: 1.9174 - val_regression_mae: 11.4219 - val_classifier_accuracy: 0.3048\n",
      "17155932\n",
      "Epoch 26/300\n",
      "727/727 [==============================] - 203s 279ms/step - loss: 27.5673 - regression_loss: 125.1061 - classifier_loss: 1.5057 - regression_mae: 8.8816 - classifier_accuracy: 0.4214 - val_loss: 34.5014 - val_regression_loss: 168.3704 - val_classifier_loss: 1.7664 - val_regression_mae: 10.3117 - val_classifier_accuracy: 0.3090\n",
      "17155932\n",
      "Epoch 27/300\n",
      "727/727 [==============================] - 198s 272ms/step - loss: 27.4403 - regression_loss: 123.8736 - classifier_loss: 1.5053 - regression_mae: 8.8565 - classifier_accuracy: 0.4228 - val_loss: 34.4322 - val_regression_loss: 172.4005 - val_classifier_loss: 1.7192 - val_regression_mae: 10.0910 - val_classifier_accuracy: 0.3612\n",
      "17155932\n",
      "Epoch 28/300\n",
      "727/727 [==============================] - 204s 281ms/step - loss: 27.4302 - regression_loss: 124.1022 - classifier_loss: 1.5020 - regression_mae: 8.8453 - classifier_accuracy: 0.4254 - val_loss: 34.3836 - val_regression_loss: 166.8421 - val_classifier_loss: 1.7699 - val_regression_mae: 10.4828 - val_classifier_accuracy: 0.3372\n",
      "17155932\n",
      "Epoch 29/300\n",
      "727/727 [==============================] - 203s 279ms/step - loss: 27.0985 - regression_loss: 121.9798 - classifier_loss: 1.4901 - regression_mae: 8.7596 - classifier_accuracy: 0.4279 - val_loss: 36.0193 - val_regression_loss: 178.6974 - val_classifier_loss: 1.8150 - val_regression_mae: 11.1466 - val_classifier_accuracy: 0.3006\n",
      "17155932\n",
      "Epoch 30/300\n",
      "727/727 [==============================] - 201s 276ms/step - loss: 27.1065 - regression_loss: 122.1533 - classifier_loss: 1.4891 - regression_mae: 8.7472 - classifier_accuracy: 0.4315 - val_loss: 34.6274 - val_regression_loss: 173.6042 - val_classifier_loss: 1.7267 - val_regression_mae: 10.2139 - val_classifier_accuracy: 0.3445\n",
      "17155932\n",
      "Epoch 31/300\n",
      "727/727 [==============================] - 200s 275ms/step - loss: 26.9777 - regression_loss: 120.9911 - classifier_loss: 1.4879 - regression_mae: 8.7147 - classifier_accuracy: 0.4283 - val_loss: 34.3618 - val_regression_loss: 172.1144 - val_classifier_loss: 1.7150 - val_regression_mae: 9.8604 - val_classifier_accuracy: 0.3664\n",
      "17155932\n",
      "Epoch 32/300\n",
      "727/727 [==============================] - 201s 276ms/step - loss: 26.9032 - regression_loss: 120.6268 - classifier_loss: 1.4841 - regression_mae: 8.6992 - classifier_accuracy: 0.4334 - val_loss: 38.5502 - val_regression_loss: 197.5352 - val_classifier_loss: 1.8797 - val_regression_mae: 11.5199 - val_classifier_accuracy: 0.3205\n",
      "17155932\n",
      "Epoch 33/300\n",
      "727/727 [==============================] - 200s 276ms/step - loss: 26.7281 - regression_loss: 119.2915 - classifier_loss: 1.4799 - regression_mae: 8.6575 - classifier_accuracy: 0.4352 - val_loss: 35.2490 - val_regression_loss: 177.5112 - val_classifier_loss: 1.7498 - val_regression_mae: 10.1914 - val_classifier_accuracy: 0.3497\n",
      "17155932\n",
      "Epoch 34/300\n",
      "727/727 [==============================] - 200s 275ms/step - loss: 26.7846 - regression_loss: 119.7719 - classifier_loss: 1.4807 - regression_mae: 8.6593 - classifier_accuracy: 0.4336 - val_loss: 33.6457 - val_regression_loss: 163.0774 - val_classifier_loss: 1.7338 - val_regression_mae: 10.1239 - val_classifier_accuracy: 0.3455\n",
      "17155932\n",
      "Epoch 35/300\n",
      "727/727 [==============================] - 200s 276ms/step - loss: 26.5315 - regression_loss: 118.0924 - classifier_loss: 1.4722 - regression_mae: 8.6172 - classifier_accuracy: 0.4340 - val_loss: 34.8470 - val_regression_loss: 168.8565 - val_classifier_loss: 1.7961 - val_regression_mae: 10.4469 - val_classifier_accuracy: 0.3184\n",
      "17155932\n",
      "Epoch 36/300\n",
      "561/727 [======================>.......] - ETA: 46s - loss: 26.2071 - regression_loss: 115.8329 - classifier_loss: 1.4624 - regression_mae: 8.5084 - classifier_accuracy: 0.4419"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 50,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mel_spect_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 15,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 8,\n",
    "        'multi_output': True,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 5,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X_mel, y, X_test_mel, y_test, X_aug_mel, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: model-20210328-002928: Is a directory\r\n",
      "grep: model-20210328-102247: Is a directory\r\n",
      "grep: model-20210328-145849: Is a directory\r\n",
      "grep: model-20210328-185850: Is a directory\r\n",
      "grep: model-20210328-223050: Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls | grep model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1D: Single input - single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2amwlmyi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 62731<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210329_155241-2amwlmyi/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210329_155241-2amwlmyi/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn_resnet_1d_mel_spect_kaldi_sub_mean_dataloader</strong>: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/2amwlmyi\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/2amwlmyi</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2amwlmyi). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mel_spect_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/30r0q4f4\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/30r0q4f4</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210329_155302-30r0q4f4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 25, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mel_spect_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210329-155302', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 20, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 0, 'multi_output': None, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 10, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "20308268\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 30)      2730        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 200, 30)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200, 30)      120         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 30)      2730        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 200, 30)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 200, 30)      120         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 200, 30)      2730        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200, 30)      120         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 30)      0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 200, 30)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 200, 30)      120         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 60)      5460        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 100, 60)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 60)      240         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 60)      10860       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 60)      240         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 100, 60)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 60)      240         re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 120)      21720       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 50, 120)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 50, 120)      480         re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 120)      43320       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 120)      480         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 50, 120)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 120)      480         re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 120)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 120)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 120)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          30976       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128)          512         re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 157,727\n",
      "Trainable params: 155,639\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 176s 234ms/step - loss: 592.9992 - mae: 18.9073 - mse: 592.9992 - val_loss: 214.0363 - val_mae: 12.5587 - val_mse: 214.0363\n",
      "20361288\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 167s 229ms/step - loss: 199.4065 - mae: 11.6136 - mse: 199.4065 - val_loss: 217.4107 - val_mae: 12.2788 - val_mse: 217.4107\n",
      "20365196\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 170s 233ms/step - loss: 184.4190 - mae: 11.0919 - mse: 184.4190 - val_loss: 211.0938 - val_mae: 12.0804 - val_mse: 211.0938\n",
      "20365200\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 162s 223ms/step - loss: 181.4107 - mae: 10.9811 - mse: 181.4107 - val_loss: 232.1105 - val_mae: 12.7296 - val_mse: 232.1105\n",
      "20365204\n",
      "Epoch 5/300\n",
      "727/727 [==============================] - 161s 221ms/step - loss: 177.4012 - mae: 10.8430 - mse: 177.4012 - val_loss: 187.1390 - val_mae: 10.8490 - val_mse: 187.1390\n",
      "20365204\n",
      "Epoch 6/300\n",
      "727/727 [==============================] - 163s 225ms/step - loss: 174.3691 - mae: 10.7215 - mse: 174.3691 - val_loss: 211.8926 - val_mae: 11.7996 - val_mse: 211.8926\n",
      "20365204\n",
      "Epoch 7/300\n",
      "727/727 [==============================] - 161s 221ms/step - loss: 170.1297 - mae: 10.5806 - mse: 170.1297 - val_loss: 200.5084 - val_mae: 11.7765 - val_mse: 200.5084\n",
      "20365204\n",
      "Epoch 8/300\n",
      "727/727 [==============================] - 162s 223ms/step - loss: 167.6624 - mae: 10.4719 - mse: 167.6624 - val_loss: 233.3279 - val_mae: 12.9785 - val_mse: 233.3279\n",
      "20365204\n",
      "Epoch 9/300\n",
      "727/727 [==============================] - 166s 229ms/step - loss: 165.3295 - mae: 10.4221 - mse: 165.3295 - val_loss: 176.0115 - val_mae: 10.9705 - val_mse: 176.0115\n",
      "20365204\n",
      "Epoch 10/300\n",
      "727/727 [==============================] - 170s 234ms/step - loss: 163.8037 - mae: 10.3682 - mse: 163.8037 - val_loss: 215.8947 - val_mae: 11.9665 - val_mse: 215.8947\n",
      "20365204\n",
      "Epoch 11/300\n",
      "727/727 [==============================] - 160s 220ms/step - loss: 160.1760 - mae: 10.2195 - mse: 160.1760 - val_loss: 185.5682 - val_mae: 10.8028 - val_mse: 185.5682\n",
      "20365204\n",
      "Epoch 12/300\n",
      "727/727 [==============================] - 157s 215ms/step - loss: 158.9895 - mae: 10.2009 - mse: 158.9895 - val_loss: 185.9354 - val_mae: 11.0827 - val_mse: 185.9354\n",
      "20365204\n",
      "Epoch 13/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 156.3766 - mae: 10.1056 - mse: 156.3766 - val_loss: 181.8014 - val_mae: 10.5096 - val_mse: 181.8014 mae: 10.1050 - - ETA: 2s - loss: 156.3710 - \n",
      "20365204\n",
      "Epoch 14/300\n",
      "727/727 [==============================] - 156s 215ms/step - loss: 155.2732 - mae: 10.0528 - mse: 155.2732 - val_loss: 177.6241 - val_mae: 11.0242 - val_mse: 177.6241\n",
      "20365204\n",
      "Epoch 15/300\n",
      "727/727 [==============================] - 162s 223ms/step - loss: 153.6282 - mae: 10.0138 - mse: 153.6282 - val_loss: 229.4599 - val_mae: 12.6622 - val_mse: 229.4599\n",
      "20365204\n",
      "Epoch 16/300\n",
      "727/727 [==============================] - 157s 215ms/step - loss: 151.0156 - mae: 9.9315 - mse: 151.0156 - val_loss: 199.7729 - val_mae: 11.6485 - val_mse: 199.7729\n",
      "20365204\n",
      "Epoch 17/300\n",
      "727/727 [==============================] - 160s 219ms/step - loss: 151.1094 - mae: 9.9080 - mse: 151.1094 - val_loss: 183.7936 - val_mae: 10.5818 - val_mse: 183.7936\n",
      "20365204\n",
      "Epoch 18/300\n",
      "727/727 [==============================] - 160s 221ms/step - loss: 148.5205 - mae: 9.8236 - mse: 148.5205 - val_loss: 185.5244 - val_mae: 11.2266 - val_mse: 185.5244\n",
      "20365204\n",
      "Epoch 19/300\n",
      "727/727 [==============================] - 155s 213ms/step - loss: 147.1672 - mae: 9.7690 - mse: 147.1672 - val_loss: 188.3701 - val_mae: 11.2283 - val_mse: 188.3701\n",
      "20365204\n",
      "Epoch 20/300\n",
      "727/727 [==============================] - 154s 212ms/step - loss: 145.7984 - mae: 9.6999 - mse: 145.7984 - val_loss: 187.5011 - val_mae: 10.8308 - val_mse: 187.5011\n",
      "20365204\n",
      "Epoch 21/300\n",
      "727/727 [==============================] - 160s 220ms/step - loss: 143.8036 - mae: 9.6390 - mse: 143.8036 - val_loss: 187.3389 - val_mae: 11.2669 - val_mse: 187.3389\n",
      "20365204\n",
      "Epoch 22/300\n",
      "727/727 [==============================] - 168s 230ms/step - loss: 141.2219 - mae: 9.5693 - mse: 141.2219 - val_loss: 188.5105 - val_mae: 11.3220 - val_mse: 188.5105\n",
      "20365204\n",
      "Epoch 23/300\n",
      "727/727 [==============================] - 167s 230ms/step - loss: 142.2884 - mae: 9.6047 - mse: 142.2884 - val_loss: 215.8377 - val_mae: 12.1606 - val_mse: 215.8377\n",
      "20365204\n",
      "Epoch 24/300\n",
      "727/727 [==============================] - 167s 229ms/step - loss: 142.0603 - mae: 9.6076 - mse: 142.0603 - val_loss: 188.7276 - val_mae: 11.3762 - val_mse: 188.7276\n",
      "20365204\n",
      "Epoch 25/300\n",
      "727/727 [==============================] - 169s 232ms/step - loss: 139.3044 - mae: 9.4797 - mse: 139.3044 - val_loss: 181.2624 - val_mae: 10.7108 - val_mse: 181.2624\n",
      "20365204\n",
      "Epoch 26/300\n",
      "727/727 [==============================] - 168s 231ms/step - loss: 139.1516 - mae: 9.4854 - mse: 139.1516 - val_loss: 176.4985 - val_mae: 10.8802 - val_mse: 176.4985\n",
      "20365204\n",
      "Epoch 27/300\n",
      "727/727 [==============================] - 159s 219ms/step - loss: 138.7024 - mae: 9.4592 - mse: 138.7024 - val_loss: 172.1817 - val_mae: 10.6291 - val_mse: 172.1817\n",
      "20365204\n",
      "Epoch 28/300\n",
      "727/727 [==============================] - 161s 221ms/step - loss: 137.9183 - mae: 9.4303 - mse: 137.9183 - val_loss: 181.7206 - val_mae: 10.9611 - val_mse: 181.7206\n",
      "20365204\n",
      "Epoch 29/300\n",
      "727/727 [==============================] - 160s 220ms/step - loss: 137.5571 - mae: 9.4260 - mse: 137.5571 - val_loss: 173.1165 - val_mae: 10.7050 - val_mse: 173.1165\n",
      "20365204\n",
      "Epoch 30/300\n",
      "727/727 [==============================] - 159s 219ms/step - loss: 136.3491 - mae: 9.3563 - mse: 136.3491 - val_loss: 182.2456 - val_mae: 11.2071 - val_mse: 182.2456\n",
      "20365204\n",
      "Epoch 31/300\n",
      "727/727 [==============================] - 161s 221ms/step - loss: 135.2964 - mae: 9.3296 - mse: 135.2964 - val_loss: 171.3859 - val_mae: 10.3910 - val_mse: 171.3859\n",
      "20365204\n",
      "Epoch 32/300\n",
      "727/727 [==============================] - 159s 219ms/step - loss: 135.3266 - mae: 9.3558 - mse: 135.3266 - val_loss: 174.5687 - val_mae: 10.7775 - val_mse: 174.5687\n",
      "20365204\n",
      "Epoch 33/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 133.4199 - mae: 9.2552 - mse: 133.4199 - val_loss: 237.5781 - val_mae: 12.9257 - val_mse: 237.5781 9.254\n",
      "20365204\n",
      "Epoch 34/300\n",
      "727/727 [==============================] - 161s 222ms/step - loss: 134.4607 - mae: 9.3030 - mse: 134.4607 - val_loss: 180.8380 - val_mae: 10.7992 - val_mse: 180.8380\n",
      "20365204\n",
      "Epoch 35/300\n",
      "727/727 [==============================] - 163s 224ms/step - loss: 131.7595 - mae: 9.2164 - mse: 131.7595 - val_loss: 203.8869 - val_mae: 11.3817 - val_mse: 203.8869\n",
      "20365204\n",
      "Epoch 36/300\n",
      "727/727 [==============================] - 162s 223ms/step - loss: 132.7227 - mae: 9.2338 - mse: 132.7227 - val_loss: 175.0261 - val_mae: 10.6506 - val_mse: 175.0261\n",
      "20365204\n",
      "Epoch 37/300\n",
      "727/727 [==============================] - 165s 227ms/step - loss: 132.0116 - mae: 9.2069 - mse: 132.0116 - val_loss: 172.8063 - val_mae: 10.5626 - val_mse: 172.8063\n",
      "20365204\n",
      "Epoch 38/300\n",
      "727/727 [==============================] - 164s 225ms/step - loss: 130.7403 - mae: 9.1366 - mse: 130.7403 - val_loss: 210.9641 - val_mae: 11.5146 - val_mse: 210.9641\n",
      "20365204\n",
      "Epoch 39/300\n",
      "727/727 [==============================] - 168s 231ms/step - loss: 129.9704 - mae: 9.1239 - mse: 129.9704 - val_loss: 183.3404 - val_mae: 10.9139 - val_mse: 183.3404\n",
      "20365204\n",
      "Epoch 40/300\n",
      "727/727 [==============================] - 170s 234ms/step - loss: 128.6500 - mae: 9.0963 - mse: 128.6500 - val_loss: 178.1617 - val_mae: 10.5927 - val_mse: 178.1617\n",
      "20365204\n",
      "Epoch 41/300\n",
      "727/727 [==============================] - 167s 229ms/step - loss: 130.0142 - mae: 9.1274 - mse: 130.0142 - val_loss: 187.9357 - val_mae: 10.9484 - val_mse: 187.9357\n",
      "20365204\n",
      "Epoch 42/300\n",
      "727/727 [==============================] - 166s 228ms/step - loss: 130.3602 - mae: 9.1393 - mse: 130.3602 - val_loss: 181.3020 - val_mae: 10.9991 - val_mse: 181.3020\n",
      "20365204\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 164s 225ms/step - loss: 128.2676 - mae: 9.0382 - mse: 128.2676 - val_loss: 176.7767 - val_mae: 10.8052 - val_mse: 176.7767\n",
      "20365204\n",
      "Epoch 44/300\n",
      "727/727 [==============================] - 160s 220ms/step - loss: 127.7409 - mae: 9.0581 - mse: 127.7409 - val_loss: 173.1110 - val_mae: 10.4508 - val_mse: 173.1110\n",
      "20365204\n",
      "Epoch 45/300\n",
      "727/727 [==============================] - 158s 217ms/step - loss: 127.7390 - mae: 9.0372 - mse: 127.7390 - val_loss: 227.0164 - val_mae: 12.5755 - val_mse: 227.0164\n",
      "20365204\n",
      "Epoch 46/300\n",
      "727/727 [==============================] - 159s 219ms/step - loss: 128.4310 - mae: 9.0580 - mse: 128.4310 - val_loss: 173.0209 - val_mae: 10.4436 - val_mse: 173.0209\n",
      "20365204\n",
      "Epoch 47/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 127.5942 - mae: 9.0182 - mse: 127.5942 - val_loss: 177.4836 - val_mae: 10.8292 - val_mse: 177.4836\n",
      "20365204\n",
      "Epoch 48/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 126.9199 - mae: 9.0117 - mse: 126.9199 - val_loss: 182.9040 - val_mae: 10.8446 - val_mse: 182.9040\n",
      "20365204\n",
      "Epoch 49/300\n",
      "727/727 [==============================] - 158s 217ms/step - loss: 125.5790 - mae: 8.9483 - mse: 125.5790 - val_loss: 176.2836 - val_mae: 10.9034 - val_mse: 176.2836\n",
      "20365204\n",
      "Epoch 50/300\n",
      "727/727 [==============================] - 151s 207ms/step - loss: 125.6664 - mae: 8.9589 - mse: 125.6664 - val_loss: 185.5968 - val_mae: 10.9965 - val_mse: 185.5968\n",
      "20365204\n",
      "Epoch 51/300\n",
      "727/727 [==============================] - 158s 217ms/step - loss: 125.6329 - mae: 8.9705 - mse: 125.6329 - val_loss: 191.8960 - val_mae: 10.4982 - val_mse: 191.8960\n",
      "20365204\n",
      "Epoch 52/300\n",
      "727/727 [==============================] - 159s 218ms/step - loss: 121.0572 - mae: 8.7808 - mse: 121.0572 - val_loss: 176.8594 - val_mae: 10.7029 - val_mse: 176.8594\n",
      "20365204\n",
      "Epoch 53/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 119.7801 - mae: 8.7167 - mse: 119.7801 - val_loss: 175.9448 - val_mae: 10.6044 - val_mse: 175.9448\n",
      "20365204\n",
      "Epoch 54/300\n",
      "727/727 [==============================] - 158s 217ms/step - loss: 119.6750 - mae: 8.7142 - mse: 119.6750 - val_loss: 175.7845 - val_mae: 10.6060 - val_mse: 175.7845\n",
      "20365204\n",
      "Epoch 55/300\n",
      "727/727 [==============================] - 155s 214ms/step - loss: 119.2544 - mae: 8.6759 - mse: 119.2544 - val_loss: 178.4391 - val_mae: 10.7289 - val_mse: 178.4391\n",
      "20365204\n",
      "Epoch 56/300\n",
      "727/727 [==============================] - 157s 216ms/step - loss: 118.5418 - mae: 8.6491 - mse: 118.5418 - val_loss: 176.2174 - val_mae: 10.6466 - val_mse: 176.2174\n",
      "20365204\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 25,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mel_spect_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 20,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 0,\n",
    "        'multi_output': None,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 10,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X_mel, y, X_test_mel, y_test, X_aug, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-20210329-155302/assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 78991<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210329_155302-30r0q4f4/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210329_155302-30r0q4f4/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>55</td></tr><tr><td>loss</td><td>118.67455</td></tr><tr><td>mae</td><td>8.64572</td></tr><tr><td>mse</td><td>118.67455</td></tr><tr><td>val_loss</td><td>176.21742</td></tr><tr><td>val_mae</td><td>10.64664</td></tr><tr><td>val_mse</td><td>176.21742</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>_runtime</td><td>9094</td></tr><tr><td>_timestamp</td><td>1617031481</td></tr><tr><td>best_val_loss</td><td>171.38591</td></tr><tr><td>best_epoch</td><td>30</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>mae</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>mse</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>val_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>val_mae</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>val_mse</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>_runtime</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>_timestamp</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn_resnet_1d_mel_spect_kaldi_sub_mean_dataloader</strong>: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/30r0q4f4\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/30r0q4f4</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models\n",
    "## CNN 1-D : Single input - single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model-20210329-155302/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 30)      2730        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 200, 30)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200, 30)      120         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 30)      2730        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 200, 30)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 200, 30)      120         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 200, 30)      2730        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200, 30)      120         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 30)      0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 200, 30)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 200, 30)      120         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 60)      5460        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 100, 60)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 60)      240         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 60)      10860       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 60)      240         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 100, 60)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 60)      240         re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 120)      21720       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 50, 120)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 50, 120)      480         re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 120)      43320       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 120)      480         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 50, 120)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 120)      480         re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 120)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 120)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 120)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          30976       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128)          512         re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 157,727\n",
      "Trainable params: 155,639\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_correct_recordings_index >>>\n",
      "1\n",
      "get_correct_recordings_index <<<\n",
      "CPU times: user 5.87 s, sys: 1.14 s, total: 7.01 s\n",
      "Wall time: 7.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/test_data.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X_test, y_test, X_spk_video_labels_test = vectors\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n",
    "\n",
    "\n",
    "X_test_mel = empty(X.shape, dtype='object')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_mel[i] = scipy.fftpack.idct(X_test[i])\n",
    "X_spk_labels_test = [''.join(x.split('-')[1:]) for x in X_spk_video_labels_test]\n",
    "test_ids_balanced = get_correct_recordings_index(X_spk_labels_test)\n",
    "len(test_ids_balanced)\n",
    "X_test = X_test[test_ids_balanced]\n",
    "y_test = y_test[test_ids_balanced]\n",
    "X_test_mel = X_test_mel[test_ids_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958,), (10972,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 958/958 [08:35<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_avg = []\n",
    "for i, test_track in enumerate(tqdm.tqdm(X_test)):\n",
    "    n_slice_to_compute = test_track.shape[0] - 200\n",
    "    current_track_pred = []\n",
    "    for idx in range(0, n_slice_to_compute, 100):        \n",
    "        sliced_track = test_track[idx:idx+200,:]\n",
    "        #print(sliced_track.shape)\n",
    "        sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "        #print(sliced_track.shape)\n",
    "        slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "        current_track_pred.append(slice_pred)\n",
    "    # Last prediction:\n",
    "    sliced_track = test_track[-200:,:]\n",
    "    sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "    #print(sliced_track.shape)\n",
    "    slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "    current_track_pred.append(slice_pred)\n",
    "    y_pred_avg.append(np.mean(current_track_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.770498279738774"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.array(y_pred_avg) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
