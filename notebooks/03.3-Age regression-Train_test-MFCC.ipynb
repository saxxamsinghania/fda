{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=6\n",
    "\n",
    "from numpy import empty\n",
    "from numpy import load\n",
    "#import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "from src.training_setup import kfold_cv, train_holdout\n",
    "\n",
    "# Set CPU as available physical device\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '.')\n",
    "my_seed = 19951008\n",
    "import random\n",
    "random.seed(my_seed)\n",
    "from numpy.random import seed\n",
    "seed(my_seed)\n",
    "from tensorflow import random\n",
    "random.set_seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 21.5 s, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/numpy_train_obj_unbalanced.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X, y, X_spk_labels, X_spk_labels_aug, X_aug, y_aug = vectors\n",
    "X_spk_labels_aug.shape\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n",
    "\n",
    "X_mel = empty(X.shape, dtype='object')\n",
    "for i in range(X.shape[0]):\n",
    "    X_mel[i] = scipy.fftpack.idct(X[i])\n",
    "X_aug_mel = empty(X_aug.shape, dtype='object')\n",
    "for i in range(X_aug.shape[0]):\n",
    "    X_aug_mel[i] = scipy.fftpack.idct(X_aug[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv('age-train.txt')\n",
    "test_metadata = pd.read_csv('age-test.txt')\n",
    "title_only_metadata = pd.read_csv('age-title_only.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.6 s, sys: 2.34 s, total: 8.94 s\n",
      "Wall time: 8.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/test_data.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X_test, y_test, X_spk_labels_test = vectors\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n",
    "\n",
    "\n",
    "X_test_mel = empty(X.shape, dtype='object')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_mel[i] = scipy.fftpack.idct(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_recordings_index(spk_labels):\n",
    "    print('get_correct_recordings_index >>>')\n",
    "    spk_labels_dict = {i:spk_labels.count(i) for i in set(spk_labels)}\n",
    "    least_freq_spk = min(list(spk_labels_dict.values()))\n",
    "    print(least_freq_spk)\n",
    "    speaker_indexes = []\n",
    "    frequency_spk_labels_dict = {}\n",
    "    for x in set(spk_labels):\n",
    "        frequency_spk_labels_dict[x] = 0\n",
    "    for index, spk_id in enumerate(spk_labels):\n",
    "        frequency_spk_labels_dict[spk_id] += 1\n",
    "        if frequency_spk_labels_dict[spk_id] > least_freq_spk:\n",
    "            next\n",
    "        else:\n",
    "            speaker_indexes.append(index)\n",
    "    print('get_correct_recordings_index <<<')\n",
    "    return speaker_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test set, currently, there are all labeled pairs person-yt videos, however we need to balance them so that each speaker has the same weight. The first step is to identify the ids of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_correct_recordings_index >>>\n",
      "1\n",
      "get_correct_recordings_index <<<\n",
      "CPU times: user 351 ms, sys: 7.69 ms, total: 359 ms\n",
      "Wall time: 354 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_spk_video_labels_test=X_spk_labels_test\n",
    "X_spk_labels_test = [''.join(x.split('-')[1:]) for x in X_spk_video_labels_test]\n",
    "test_ids_balanced = get_correct_recordings_index(X_spk_labels_test)\n",
    "len(test_ids_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we'll have 958 test records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[test_ids_balanced]\n",
    "y_test = y_test[test_ids_balanced]\n",
    "X_test_mel = X_test_mel[test_ids_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958,), (958,), (958,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_test_mel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train\n",
    "## CNN 1D : Multi input - Multi output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse_plus_cross']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhechmik\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/khaled/miniconda3/envs/tf/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/3lhmicio\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/3lhmicio</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_002929-3lhmicio</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 50, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mfcc_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse_plus_cross', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210328-002928', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 15, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 8, 'multi_output': True, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 5, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "13689572\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 200, 30)      2730        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 200, 30)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 30)      120         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 200, 30)      2730        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 200, 30)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 30)      120         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 30)      2730        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 30)      120         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 200, 30)      0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 200, 30)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 30)      120         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 100, 30)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 100, 60)      5460        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 100, 60)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 60)      240         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 100, 60)      10860       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 60)      240         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 100, 60)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 60)      240         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 50, 120)      21720       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 50, 120)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 120)      480         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 50, 120)      43320       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 120)      480         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 50, 120)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 120)      480         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 120)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 120)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          30976       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 8)            1032        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 158,759\n",
      "Trainable params: 156,671\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n",
      "multioutput_y_preparation >>>\n",
      "Train label encoder output: (92955,)\n",
      "Test label encoder output: (958,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khaled/miniconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 292s 384ms/step - loss: 86.1288 - regression_loss: 647.5984 - classifier_loss: 2.1369 - regression_mae: 19.3887 - classifier_accuracy: 0.2289 - val_loss: 38.9540 - val_regression_loss: 198.6782 - val_classifier_loss: 1.9086 - val_regression_mae: 11.9303 - val_classifier_accuracy: 0.2589\n",
      "13940532\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 294s 404ms/step - loss: 35.9950 - regression_loss: 190.5483 - classifier_loss: 1.6940 - regression_mae: 11.2896 - classifier_accuracy: 0.3343 - val_loss: 35.9439 - val_regression_loss: 180.1736 - val_classifier_loss: 1.7927 - val_regression_mae: 11.0319 - val_classifier_accuracy: 0.2902\n",
      "13966768\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 286s 393ms/step - loss: 34.1584 - regression_loss: 176.6162 - classifier_loss: 1.6497 - regression_mae: 10.7831 - classifier_accuracy: 0.3575 - val_loss: 38.7087 - val_regression_loss: 196.4533 - val_classifier_loss: 1.9063 - val_regression_mae: 11.7571 - val_classifier_accuracy: 0.2599\n",
      "13974076\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 287s 394ms/step - loss: 33.4938 - regression_loss: 171.2180 - classifier_loss: 1.6372 - regression_mae: 10.5919 - classifier_accuracy: 0.3648 - val_loss: 34.6234 - val_regression_loss: 175.9381 - val_classifier_loss: 1.7030 - val_regression_mae: 10.3854 - val_classifier_accuracy: 0.3486\n",
      "13974076\n",
      "Epoch 5/300\n",
      "434/727 [================>.............] - ETA: 1:47 - loss: 32.5622 - regression_loss: 163.4464 - classifier_loss: 1.6218 - regression_mae: 10.3079 - classifier_accuracy: 0.3763"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 50,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mfcc_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 15,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 8,\n",
    "        'multi_output': True,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 5,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X, y, X_test, y_test, X_aug, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1D: Single input - single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/2svk0fa1\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/2svk0fa1</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_102247-2svk0fa1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 30, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mfcc_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210328-102247', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 20, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 0, 'multi_output': None, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 10, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "17067440\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 30)      2730        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 200, 30)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200, 30)      120         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 30)      2730        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 200, 30)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 200, 30)      120         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 200, 30)      2730        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200, 30)      120         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 30)      0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 200, 30)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 200, 30)      120         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 60)      5460        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 100, 60)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 60)      240         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 60)      10860       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 60)      240         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 100, 60)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 60)      240         re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 120)      21720       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 50, 120)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 50, 120)      480         re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 120)      43320       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 120)      480         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 50, 120)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 120)      480         re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 120)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 120)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 120)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          30976       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128)          512         re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 157,727\n",
      "Trainable params: 155,639\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 299s 393ms/step - loss: 595.8489 - mae: 19.0339 - mse: 595.8489 - val_loss: 181.8343 - val_mae: 11.1196 - val_mse: 181.8343\n",
      "17141124\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 291s 400ms/step - loss: 191.1072 - mae: 11.3215 - mse: 191.1072 - val_loss: 181.2869 - val_mae: 11.1771 - val_mse: 181.2869\n",
      "17151928\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 286s 394ms/step - loss: 176.7495 - mae: 10.8263 - mse: 176.7495 - val_loss: 248.6233 - val_mae: 13.1497 - val_mse: 248.6233\n",
      "17158620\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 287s 394ms/step - loss: 169.8154 - mae: 10.5528 - mse: 169.8154 - val_loss: 316.4139 - val_mae: 14.7053 - val_mse: 316.4139\n",
      "17158620\n",
      "Epoch 5/300\n",
      "727/727 [==============================] - 288s 395ms/step - loss: 162.6266 - mae: 10.2964 - mse: 162.6266 - val_loss: 179.2753 - val_mae: 10.7207 - val_mse: 179.2753\n",
      "17158620\n",
      "Epoch 6/300\n",
      "727/727 [==============================] - 289s 397ms/step - loss: 159.7149 - mae: 10.1919 - mse: 159.7149 - val_loss: 202.3097 - val_mae: 11.9898 - val_mse: 202.3097\n",
      "17169444\n",
      "Epoch 7/300\n",
      "727/727 [==============================] - 286s 394ms/step - loss: 155.9073 - mae: 10.0781 - mse: 155.9073 - val_loss: 233.3118 - val_mae: 12.6582 - val_mse: 233.3118\n",
      "17169444\n",
      "Epoch 8/300\n",
      "727/727 [==============================] - 282s 388ms/step - loss: 153.4853 - mae: 9.9546 - mse: 153.4853 - val_loss: 171.6614 - val_mae: 10.1208 - val_mse: 171.6614\n",
      "17169444\n",
      "Epoch 9/300\n",
      "727/727 [==============================] - 286s 393ms/step - loss: 150.7770 - mae: 9.8644 - mse: 150.7770 - val_loss: 211.2620 - val_mae: 11.9902 - val_mse: 211.2620\n",
      "17169444\n",
      "Epoch 10/300\n",
      "727/727 [==============================] - 284s 391ms/step - loss: 146.5864 - mae: 9.7201 - mse: 146.5864 - val_loss: 189.2372 - val_mae: 11.0252 - val_mse: 189.2372\n",
      "17169444\n",
      "Epoch 11/300\n",
      "727/727 [==============================] - 285s 392ms/step - loss: 146.6888 - mae: 9.7304 - mse: 146.6888 - val_loss: 197.6062 - val_mae: 11.3986 - val_mse: 197.6062\n",
      "17169444\n",
      "Epoch 12/300\n",
      "727/727 [==============================] - 281s 387ms/step - loss: 143.8002 - mae: 9.6240 - mse: 143.8002 - val_loss: 167.3904 - val_mae: 10.3725 - val_mse: 167.3904\n",
      "17169444\n",
      "Epoch 13/300\n",
      "727/727 [==============================] - 265s 364ms/step - loss: 141.7617 - mae: 9.5460 - mse: 141.7617 - val_loss: 199.7974 - val_mae: 11.6650 - val_mse: 199.7974\n",
      "17169444\n",
      "Epoch 14/300\n",
      "727/727 [==============================] - 252s 346ms/step - loss: 138.2306 - mae: 9.4095 - mse: 138.2306 - val_loss: 164.8696 - val_mae: 10.0962 - val_mse: 164.8696\n",
      "17169444\n",
      "Epoch 15/300\n",
      "727/727 [==============================] - 257s 353ms/step - loss: 136.3339 - mae: 9.3524 - mse: 136.3339 - val_loss: 172.1374 - val_mae: 10.3211 - val_mse: 172.1374\n",
      "17169444\n",
      "Epoch 16/300\n",
      "727/727 [==============================] - 282s 387ms/step - loss: 136.0199 - mae: 9.3169 - mse: 136.0199 - val_loss: 258.1932 - val_mae: 13.4705 - val_mse: 258.1932\n",
      "17169444\n",
      "Epoch 17/300\n",
      "727/727 [==============================] - 285s 393ms/step - loss: 132.6035 - mae: 9.1896 - mse: 132.6035 - val_loss: 176.9737 - val_mae: 10.3396 - val_mse: 176.9737\n",
      "17169444\n",
      "Epoch 18/300\n",
      "727/727 [==============================] - 290s 398ms/step - loss: 132.4903 - mae: 9.1999 - mse: 132.4903 - val_loss: 169.4853 - val_mae: 10.2286 - val_mse: 169.4853\n",
      "17169444\n",
      "Epoch 19/300\n",
      "727/727 [==============================] - 286s 394ms/step - loss: 131.3539 - mae: 9.1404 - mse: 131.3539 - val_loss: 167.3962 - val_mae: 10.0197 - val_mse: 167.3962\n",
      "17169444\n",
      "Epoch 20/300\n",
      "727/727 [==============================] - 290s 399ms/step - loss: 129.6434 - mae: 9.0627 - mse: 129.6434 - val_loss: 207.6311 - val_mae: 11.7136 - val_mse: 207.6311\n",
      "17169444\n",
      "Epoch 21/300\n",
      "727/727 [==============================] - 285s 392ms/step - loss: 127.5252 - mae: 9.0050 - mse: 127.5252 - val_loss: 208.7678 - val_mae: 11.4264 - val_mse: 208.7678\n",
      "17169444\n",
      "Epoch 22/300\n",
      "727/727 [==============================] - 293s 403ms/step - loss: 126.8513 - mae: 8.9634 - mse: 126.8513 - val_loss: 225.7807 - val_mae: 12.1962 - val_mse: 225.7807\n",
      "17169444\n",
      "Epoch 23/300\n",
      "727/727 [==============================] - 284s 390ms/step - loss: 125.4266 - mae: 8.8995 - mse: 125.4266 - val_loss: 163.4485 - val_mae: 10.2412 - val_mse: 163.4485\n",
      "17169444\n",
      "Epoch 24/300\n",
      "727/727 [==============================] - 266s 367ms/step - loss: 124.9630 - mae: 8.8929 - mse: 124.9630 - val_loss: 196.3136 - val_mae: 11.4068 - val_mse: 196.3136\n",
      "17169444\n",
      "Epoch 25/300\n",
      "727/727 [==============================] - 264s 363ms/step - loss: 123.9322 - mae: 8.8416 - mse: 123.9322 - val_loss: 190.7812 - val_mae: 10.9775 - val_mse: 190.7812\n",
      "17169444\n",
      "Epoch 26/300\n",
      "727/727 [==============================] - 282s 387ms/step - loss: 122.8307 - mae: 8.8034 - mse: 122.8307 - val_loss: 180.1813 - val_mae: 10.6357 - val_mse: 180.1813\n",
      "17169444\n",
      "Epoch 27/300\n",
      "727/727 [==============================] - 294s 405ms/step - loss: 121.6997 - mae: 8.7852 - mse: 121.6997 - val_loss: 168.9486 - val_mae: 10.0606 - val_mse: 168.9486\n",
      "17169444\n",
      "Epoch 28/300\n",
      "727/727 [==============================] - 271s 373ms/step - loss: 121.8381 - mae: 8.7609 - mse: 121.8381 - val_loss: 203.1041 - val_mae: 11.9127 - val_mse: 203.1041\n",
      "17169444\n",
      "Epoch 29/300\n",
      "727/727 [==============================] - 275s 378ms/step - loss: 119.0029 - mae: 8.6745 - mse: 119.0029 - val_loss: 162.2285 - val_mae: 10.1285 - val_mse: 162.2285\n",
      "17169444\n",
      "Epoch 30/300\n",
      "727/727 [==============================] - 271s 373ms/step - loss: 119.7974 - mae: 8.6915 - mse: 119.7974 - val_loss: 194.4969 - val_mae: 11.2094 - val_mse: 194.4969\n",
      "17169444\n",
      "Epoch 31/300\n",
      "727/727 [==============================] - 263s 362ms/step - loss: 118.9457 - mae: 8.6586 - mse: 118.9457 - val_loss: 174.0795 - val_mae: 10.1324 - val_mse: 174.0795\n",
      "17169444\n",
      "Epoch 32/300\n",
      "727/727 [==============================] - 273s 375ms/step - loss: 117.2805 - mae: 8.5941 - mse: 117.2805 - val_loss: 226.2483 - val_mae: 12.7048 - val_mse: 226.2483\n",
      "17169444\n",
      "Epoch 33/300\n",
      "727/727 [==============================] - 267s 367ms/step - loss: 118.4249 - mae: 8.6410 - mse: 118.4249 - val_loss: 192.7448 - val_mae: 11.1927 - val_mse: 192.7448\n",
      "17169444\n",
      "Epoch 34/300\n",
      "727/727 [==============================] - 269s 370ms/step - loss: 115.7434 - mae: 8.5479 - mse: 115.7434 - val_loss: 179.0000 - val_mae: 10.1967 - val_mse: 179.0000\n",
      "17169444\n",
      "Epoch 35/300\n",
      "727/727 [==============================] - 268s 369ms/step - loss: 116.4183 - mae: 8.5572 - mse: 116.4183 - val_loss: 165.9848 - val_mae: 10.0779 - val_mse: 165.9848\n",
      "17169444\n",
      "Epoch 36/300\n",
      "727/727 [==============================] - 267s 367ms/step - loss: 114.5764 - mae: 8.4730 - mse: 114.5764 - val_loss: 182.3034 - val_mae: 10.5135 - val_mse: 182.3034\n",
      "17169444\n",
      "Epoch 37/300\n",
      "727/727 [==============================] - 268s 369ms/step - loss: 113.6126 - mae: 8.4546 - mse: 113.6126 - val_loss: 171.2328 - val_mae: 10.2555 - val_mse: 171.2328\n",
      "17169444\n",
      "Epoch 38/300\n",
      "727/727 [==============================] - 255s 351ms/step - loss: 111.6405 - mae: 8.3725 - mse: 111.6405 - val_loss: 176.0514 - val_mae: 10.5989 - val_mse: 176.0514\n",
      "17169444\n",
      "Epoch 39/300\n",
      "727/727 [==============================] - 270s 371ms/step - loss: 111.0535 - mae: 8.3345 - mse: 111.0535 - val_loss: 173.4574 - val_mae: 10.5860 - val_mse: 173.4574\n",
      "17169444\n",
      "Epoch 40/300\n",
      "727/727 [==============================] - 295s 406ms/step - loss: 109.4809 - mae: 8.2792 - mse: 109.4809 - val_loss: 173.4210 - val_mae: 10.4417 - val_mse: 173.4210\n",
      "17169444\n",
      "Epoch 41/300\n",
      "727/727 [==============================] - 297s 409ms/step - loss: 107.1404 - mae: 8.1909 - mse: 107.1404 - val_loss: 177.7532 - val_mae: 10.5432 - val_mse: 177.7532\n",
      "17169444\n",
      "Epoch 42/300\n",
      "727/727 [==============================] - 298s 410ms/step - loss: 104.8788 - mae: 8.0729 - mse: 104.8788 - val_loss: 171.1577 - val_mae: 10.3202 - val_mse: 171.1577\n",
      "17169444\n",
      "Epoch 43/300\n",
      "727/727 [==============================] - 293s 404ms/step - loss: 105.2705 - mae: 8.1071 - mse: 105.2705 - val_loss: 171.2127 - val_mae: 10.3997 - val_mse: 171.2127\n",
      "17169444\n",
      "Epoch 44/300\n",
      "727/727 [==============================] - 296s 406ms/step - loss: 106.0908 - mae: 8.1034 - mse: 106.0908 - val_loss: 171.4495 - val_mae: 10.3139 - val_mse: 171.4495\n",
      "17169444\n",
      "Epoch 45/300\n",
      "727/727 [==============================] - 278s 383ms/step - loss: 104.2612 - mae: 8.0580 - mse: 104.2612 - val_loss: 174.2777 - val_mae: 10.3994 - val_mse: 174.2777\n",
      "17169444\n",
      "Epoch 46/300\n",
      "727/727 [==============================] - 283s 389ms/step - loss: 104.7829 - mae: 8.0705 - mse: 104.7829 - val_loss: 174.4976 - val_mae: 10.4179 - val_mse: 174.4976\n",
      "17169444\n",
      "Epoch 47/300\n",
      "727/727 [==============================] - 284s 391ms/step - loss: 104.0524 - mae: 8.0347 - mse: 104.0524 - val_loss: 173.4973 - val_mae: 10.4232 - val_mse: 173.4973\n",
      "17169444\n",
      "Epoch 48/300\n",
      "727/727 [==============================] - 279s 383ms/step - loss: 103.9788 - mae: 8.0225 - mse: 103.9788 - val_loss: 170.8438 - val_mae: 10.3430 - val_mse: 170.8438\n",
      "17169444\n",
      "Epoch 49/300\n",
      "727/727 [==============================] - 281s 386ms/step - loss: 103.5275 - mae: 8.0094 - mse: 103.5275 - val_loss: 171.4783 - val_mae: 10.3307 - val_mse: 171.4783\n",
      "17169444\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 30,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mfcc_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 20,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 0,\n",
    "        'multi_output': None,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 10,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X, y, X_test, y_test, X_aug, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-20210328-102247/assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 84259<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_102247-2svk0fa1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_102247-2svk0fa1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>48</td></tr><tr><td>loss</td><td>103.74007</td></tr><tr><td>mae</td><td>8.0165</td></tr><tr><td>mse</td><td>103.74007</td></tr><tr><td>val_loss</td><td>171.47829</td></tr><tr><td>val_mae</td><td>10.3307</td></tr><tr><td>val_mse</td><td>171.47829</td></tr><tr><td>_step</td><td>48</td></tr><tr><td>_runtime</td><td>13765</td></tr><tr><td>_timestamp</td><td>1616929934</td></tr><tr><td>best_val_loss</td><td>162.22855</td></tr><tr><td>best_epoch</td><td>28</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▂▅█▂▄▁▃▂▁▃▁▁▂▁▁▃▃▁▃▂▂▃▁▂▂▂▂▁▂▁▂▂▂▁▁▂▂▂▁</td></tr><tr><td>val_mae</td><td>▃▃▆█▂▅▁▄▃▂▃▁▁▁▁▁▄▃▁▃▂▂▄▁▃▁▃▁▁▂▁▂▂▂▁▁▂▂▂▁</td></tr><tr><td>val_mse</td><td>▂▂▅█▂▄▁▃▂▁▃▁▁▂▁▁▃▃▁▃▂▂▃▁▂▂▂▂▁▂▁▂▂▂▁▁▂▂▂▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong>: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/2svk0fa1\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/2svk0fa1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1D : decreasing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.training_setup' from '/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/src/training_setup.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from src import resnets\n",
    "from src import training_setup\n",
    "reload(resnets)\n",
    "reload(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/2dzgn0j8\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/2dzgn0j8</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_145849-2dzgn0j8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 30, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mfcc_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210328-145849', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 20, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 0, 'multi_output': None, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 10, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'decreasing_filters': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "20495200\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 200, 30)      2730        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 200, 30)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 200, 30)      120         re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 200, 30)      2730        batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 200, 30)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 200, 30)      120         re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 200, 30)      2730        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 200, 30)      120         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 200, 30)      0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 200, 30)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 200, 30)      120         re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 100, 15)      1365        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 100, 15)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 100, 15)      60          re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 100, 15)      690         batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 100, 15)      60          conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 100, 15)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 100, 15)      60          re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 50, 15)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 50, 7)        322         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 50, 7)        0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 50, 7)        28          re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 50, 7)        154         batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 50, 7)        28          conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 50, 7)        0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 50, 7)        28          re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 7)            0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7)            0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7)            0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256)          1024        re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256)          0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 128)          512         re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,074\n",
      "Trainable params: 46,934\n",
      "Non-trainable params: 1,140\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 195s 249ms/step - loss: 610.5267 - mae: 19.0314 - mse: 610.5267 - val_loss: 207.1350 - val_mae: 11.5085 - val_mse: 207.1350\n",
      "20544912\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 174s 239ms/step - loss: 195.6135 - mae: 11.4744 - mse: 195.6135 - val_loss: 215.9154 - val_mae: 12.4918 - val_mse: 215.9154\n",
      "20545184\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 181s 249ms/step - loss: 177.9529 - mae: 10.8646 - mse: 177.9529 - val_loss: 171.6050 - val_mae: 10.9044 - val_mse: 171.6050\n",
      "20545184\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 185s 255ms/step - loss: 174.7715 - mae: 10.7415 - mse: 174.7715 - val_loss: 219.6935 - val_mae: 12.6061 - val_mse: 219.6935\n",
      "20545184\n",
      "Epoch 5/300\n",
      "727/727 [==============================] - 178s 245ms/step - loss: 168.6065 - mae: 10.5168 - mse: 168.6065 - val_loss: 216.1697 - val_mae: 12.3127 - val_mse: 216.1697\n",
      "20545184\n",
      "Epoch 6/300\n",
      "727/727 [==============================] - 186s 255ms/step - loss: 165.7393 - mae: 10.4292 - mse: 165.7393 - val_loss: 211.0554 - val_mae: 12.0665 - val_mse: 211.0554\n",
      "20545184\n",
      "Epoch 7/300\n",
      "727/727 [==============================] - 191s 263ms/step - loss: 162.8405 - mae: 10.3052 - mse: 162.8405 - val_loss: 171.5326 - val_mae: 10.5004 - val_mse: 171.5326\n",
      "20545184\n",
      "Epoch 8/300\n",
      "727/727 [==============================] - 186s 255ms/step - loss: 159.4889 - mae: 10.1686 - mse: 159.4889 - val_loss: 189.2222 - val_mae: 11.6000 - val_mse: 189.2222\n",
      "20545184\n",
      "Epoch 9/300\n",
      "727/727 [==============================] - 191s 262ms/step - loss: 156.5826 - mae: 10.0602 - mse: 156.5826 - val_loss: 207.4620 - val_mae: 12.2772 - val_mse: 207.4620\n",
      "20545184\n",
      "Epoch 10/300\n",
      "727/727 [==============================] - 183s 252ms/step - loss: 154.4339 - mae: 10.0146 - mse: 154.4339 - val_loss: 168.2718 - val_mae: 10.5405 - val_mse: 168.2718\n",
      "20545184\n",
      "Epoch 11/300\n",
      "727/727 [==============================] - 186s 256ms/step - loss: 151.0628 - mae: 9.8935 - mse: 151.0628 - val_loss: 213.1710 - val_mae: 12.3171 - val_mse: 213.1710loss: 151.0632 - \n",
      "20545184\n",
      "Epoch 12/300\n",
      "727/727 [==============================] - 183s 252ms/step - loss: 149.9127 - mae: 9.8609 - mse: 149.9127 - val_loss: 180.0585 - val_mae: 10.8626 - val_mse: 180.0585\n",
      "20545184\n",
      "Epoch 13/300\n",
      "727/727 [==============================] - 181s 249ms/step - loss: 146.2320 - mae: 9.7258 - mse: 146.2320 - val_loss: 167.2990 - val_mae: 10.6207 - val_mse: 167.2990\n",
      "20545184\n",
      "Epoch 14/300\n",
      "727/727 [==============================] - 183s 252ms/step - loss: 146.7526 - mae: 9.7511 - mse: 146.7526 - val_loss: 173.7610 - val_mae: 10.6192 - val_mse: 173.7610\n",
      "20545184\n",
      "Epoch 15/300\n",
      "727/727 [==============================] - 178s 245ms/step - loss: 143.5612 - mae: 9.5935 - mse: 143.5612 - val_loss: 177.5655 - val_mae: 10.2819 - val_mse: 177.5655\n",
      "20545184\n",
      "Epoch 16/300\n",
      "727/727 [==============================] - 177s 243ms/step - loss: 143.0677 - mae: 9.5971 - mse: 143.0677 - val_loss: 203.9273 - val_mae: 12.1218 - val_mse: 203.9273\n",
      "20545184\n",
      "Epoch 17/300\n",
      "727/727 [==============================] - 181s 249ms/step - loss: 141.0496 - mae: 9.5401 - mse: 141.0496 - val_loss: 164.3764 - val_mae: 10.5647 - val_mse: 164.3764\n",
      "20545184\n",
      "Epoch 18/300\n",
      "727/727 [==============================] - 184s 253ms/step - loss: 141.0830 - mae: 9.5173 - mse: 141.0830 - val_loss: 174.7868 - val_mae: 10.9652 - val_mse: 174.7868\n",
      "20545184\n",
      "Epoch 19/300\n",
      "727/727 [==============================] - 178s 245ms/step - loss: 139.6575 - mae: 9.4828 - mse: 139.6575 - val_loss: 165.8643 - val_mae: 10.0983 - val_mse: 165.8643\n",
      "20545184\n",
      "Epoch 20/300\n",
      "727/727 [==============================] - 176s 242ms/step - loss: 139.2594 - mae: 9.4616 - mse: 139.2594 - val_loss: 176.9721 - val_mae: 11.2120 - val_mse: 176.9721\n",
      "20545184\n",
      "Epoch 21/300\n",
      "727/727 [==============================] - 174s 239ms/step - loss: 137.7409 - mae: 9.4199 - mse: 137.7409 - val_loss: 177.8651 - val_mae: 10.9797 - val_mse: 177.8651\n",
      "20545184\n",
      "Epoch 22/300\n",
      "727/727 [==============================] - 173s 239ms/step - loss: 137.0786 - mae: 9.4107 - mse: 137.0786 - val_loss: 170.0078 - val_mae: 10.5828 - val_mse: 170.0078loss: 137.0762 - mae: 9.4107 - mse: \n",
      "20545184\n",
      "Epoch 23/300\n",
      "727/727 [==============================] - 179s 246ms/step - loss: 137.2909 - mae: 9.4008 - mse: 137.2909 - val_loss: 167.5926 - val_mae: 10.4854 - val_mse: 167.5926\n",
      "20545184\n",
      "Epoch 24/300\n",
      "727/727 [==============================] - 169s 232ms/step - loss: 135.4403 - mae: 9.3378 - mse: 135.4403 - val_loss: 184.4967 - val_mae: 11.2639 - val_mse: 184.4967\n",
      "20545184\n",
      "Epoch 25/300\n",
      "727/727 [==============================] - 166s 228ms/step - loss: 134.4138 - mae: 9.2995 - mse: 134.4138 - val_loss: 175.7626 - val_mae: 10.4053 - val_mse: 175.7626\n",
      "20545184\n",
      "Epoch 26/300\n",
      "727/727 [==============================] - 166s 229ms/step - loss: 132.9404 - mae: 9.2324 - mse: 132.9404 - val_loss: 209.5454 - val_mae: 12.0374 - val_mse: 209.5454\n",
      "20545184\n",
      "Epoch 27/300\n",
      "727/727 [==============================] - 169s 233ms/step - loss: 132.5703 - mae: 9.2359 - mse: 132.5703 - val_loss: 165.0774 - val_mae: 10.3043 - val_mse: 165.0774\n",
      "20545184\n",
      "Epoch 28/300\n",
      "727/727 [==============================] - 167s 229ms/step - loss: 132.1115 - mae: 9.2278 - mse: 132.1115 - val_loss: 163.8048 - val_mae: 9.9605 - val_mse: 163.8048.1181 - mae\n",
      "20545184\n",
      "Epoch 29/300\n",
      "727/727 [==============================] - 165s 227ms/step - loss: 131.0794 - mae: 9.1808 - mse: 131.0794 - val_loss: 232.9379 - val_mae: 12.3866 - val_mse: 232.9379\n",
      "20545184\n",
      "Epoch 30/300\n",
      "727/727 [==============================] - 173s 238ms/step - loss: 130.1810 - mae: 9.1595 - mse: 130.1810 - val_loss: 190.8520 - val_mae: 11.5549 - val_mse: 190.8520130.1514 - ma\n",
      "20545184\n",
      "Epoch 31/300\n",
      "727/727 [==============================] - 176s 243ms/step - loss: 129.5976 - mae: 9.1245 - mse: 129.5976 - val_loss: 186.9465 - val_mae: 11.3043 - val_mse: 186.9465\n",
      "20545184\n",
      "Epoch 32/300\n",
      "727/727 [==============================] - 175s 241ms/step - loss: 128.3773 - mae: 9.0442 - mse: 128.3773 - val_loss: 168.2303 - val_mae: 10.1806 - val_mse: 168.2303\n",
      "20545184\n",
      "Epoch 33/300\n",
      "727/727 [==============================] - 177s 244ms/step - loss: 128.7917 - mae: 9.0735 - mse: 128.7917 - val_loss: 194.3757 - val_mae: 11.3987 - val_mse: 194.3757 128.7828 - mae: 9.0730 -\n",
      "20545184\n",
      "Epoch 34/300\n",
      "727/727 [==============================] - 187s 257ms/step - loss: 129.1568 - mae: 9.0919 - mse: 129.1568 - val_loss: 163.0003 - val_mae: 10.1213 - val_mse: 163.0003\n",
      "20545184\n",
      "Epoch 35/300\n",
      "727/727 [==============================] - 186s 256ms/step - loss: 128.7196 - mae: 9.0718 - mse: 128.7196 - val_loss: 162.7996 - val_mae: 10.3464 - val_mse: 162.7996\n",
      "20545184\n",
      "Epoch 36/300\n",
      "727/727 [==============================] - 183s 252ms/step - loss: 127.9409 - mae: 9.0703 - mse: 127.9409 - val_loss: 167.5807 - val_mae: 10.6315 - val_mse: 167.5807\n",
      "20545184\n",
      "Epoch 37/300\n",
      "727/727 [==============================] - 185s 255ms/step - loss: 126.6394 - mae: 9.0250 - mse: 126.6394 - val_loss: 167.5929 - val_mae: 10.1479 - val_mse: 167.5929\n",
      "20545184\n",
      "Epoch 38/300\n",
      "727/727 [==============================] - 185s 254ms/step - loss: 126.9310 - mae: 9.0220 - mse: 126.9310 - val_loss: 164.9895 - val_mae: 10.4648 - val_mse: 164.9895\n",
      "20545184\n",
      "Epoch 39/300\n",
      "727/727 [==============================] - 187s 257ms/step - loss: 127.9239 - mae: 9.0510 - mse: 127.9239 - val_loss: 161.9390 - val_mae: 10.3258 - val_mse: 161.9390\n",
      "20545184\n",
      "Epoch 40/300\n",
      "727/727 [==============================] - 180s 247ms/step - loss: 126.6717 - mae: 9.0208 - mse: 126.6717 - val_loss: 162.9453 - val_mae: 10.2670 - val_mse: 162.9453\n",
      "20545184\n",
      "Epoch 41/300\n",
      "727/727 [==============================] - 171s 235ms/step - loss: 125.8260 - mae: 8.9838 - mse: 125.8260 - val_loss: 254.5100 - val_mae: 13.4320 - val_mse: 254.5100\n",
      "20545184\n",
      "Epoch 42/300\n",
      "727/727 [==============================] - 184s 253ms/step - loss: 125.5104 - mae: 8.9649 - mse: 125.5104 - val_loss: 180.7164 - val_mae: 10.2409 - val_mse: 180.7164\n",
      "20545184\n",
      "Epoch 43/300\n",
      "727/727 [==============================] - 189s 260ms/step - loss: 126.0459 - mae: 8.9798 - mse: 126.0459 - val_loss: 163.7718 - val_mae: 10.5205 - val_mse: 163.7718\n",
      "20545184\n",
      "Epoch 44/300\n",
      "727/727 [==============================] - 190s 261ms/step - loss: 125.5271 - mae: 8.9531 - mse: 125.5271 - val_loss: 163.1201 - val_mae: 10.3544 - val_mse: 163.1201\n",
      "20545184\n",
      "Epoch 45/300\n",
      "727/727 [==============================] - 182s 250ms/step - loss: 126.5954 - mae: 9.0166 - mse: 126.5954 - val_loss: 186.4010 - val_mae: 11.2604 - val_mse: 186.4010\n",
      "20545184\n",
      "Epoch 46/300\n",
      "727/727 [==============================] - 186s 256ms/step - loss: 125.1940 - mae: 8.9189 - mse: 125.1940 - val_loss: 165.0283 - val_mae: 10.2587 - val_mse: 165.0283\n",
      "20545184\n",
      "Epoch 47/300\n",
      "727/727 [==============================] - 186s 256ms/step - loss: 124.1687 - mae: 8.9077 - mse: 124.1687 - val_loss: 164.1771 - val_mae: 10.0995 - val_mse: 164.1771\n",
      "20545184\n",
      "Epoch 48/300\n",
      "727/727 [==============================] - 189s 260ms/step - loss: 124.6512 - mae: 8.9416 - mse: 124.6512 - val_loss: 176.9219 - val_mae: 10.8934 - val_mse: 176.9219\n",
      "20545184\n",
      "Epoch 49/300\n",
      "727/727 [==============================] - 196s 270ms/step - loss: 121.7134 - mae: 8.8058 - mse: 121.7134 - val_loss: 167.7864 - val_mae: 10.5320 - val_mse: 167.7864\n",
      "20545184\n",
      "Epoch 50/300\n",
      "727/727 [==============================] - 193s 265ms/step - loss: 120.9735 - mae: 8.7772 - mse: 120.9735 - val_loss: 166.2437 - val_mae: 10.5249 - val_mse: 166.2437\n",
      "20545184\n",
      "Epoch 51/300\n",
      "727/727 [==============================] - 170s 234ms/step - loss: 121.0338 - mae: 8.7836 - mse: 121.0338 - val_loss: 163.7684 - val_mae: 10.3464 - val_mse: 163.7684\n",
      "20545184\n",
      "Epoch 52/300\n",
      "727/727 [==============================] - 177s 243ms/step - loss: 119.9909 - mae: 8.7228 - mse: 119.9909 - val_loss: 167.2821 - val_mae: 10.5334 - val_mse: 167.2821\n",
      "20545184\n",
      "Epoch 53/300\n",
      "727/727 [==============================] - 176s 242ms/step - loss: 118.9765 - mae: 8.7372 - mse: 118.9765 - val_loss: 161.3846 - val_mae: 10.2482 - val_mse: 161.3846\n",
      "20545184\n",
      "Epoch 54/300\n",
      "727/727 [==============================] - 180s 247ms/step - loss: 118.9020 - mae: 8.7069 - mse: 118.9020 - val_loss: 164.0244 - val_mae: 10.4102 - val_mse: 164.0244\n",
      "20545184\n",
      "Epoch 55/300\n",
      "727/727 [==============================] - 168s 231ms/step - loss: 119.4845 - mae: 8.7235 - mse: 119.4845 - val_loss: 165.0917 - val_mae: 10.4021 - val_mse: 165.0917.7238 - mse: 1\n",
      "20545184\n",
      "Epoch 56/300\n",
      "727/727 [==============================] - 172s 236ms/step - loss: 118.3194 - mae: 8.6821 - mse: 118.3194 - val_loss: 164.8108 - val_mae: 10.3625 - val_mse: 164.8108\n",
      "20545184\n",
      "Epoch 57/300\n",
      "727/727 [==============================] - 180s 247ms/step - loss: 118.6021 - mae: 8.6978 - mse: 118.6021 - val_loss: 163.4242 - val_mae: 10.3226 - val_mse: 163.4242\n",
      "20545184\n",
      "Epoch 58/300\n",
      "727/727 [==============================] - 167s 230ms/step - loss: 118.0737 - mae: 8.6660 - mse: 118.0737 - val_loss: 165.0312 - val_mae: 10.4468 - val_mse: 165.0312\n",
      "20545184\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))\n",
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 30,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mfcc_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 20,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 0,\n",
    "        'multi_output': None,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 10,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True,\n",
    "        'decreasing_filters': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X, y, X_test, y_test, X_aug, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-20210328-145849/assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2400<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_145849-2dzgn0j8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_145849-2dzgn0j8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>57</td></tr><tr><td>loss</td><td>118.54803</td></tr><tr><td>mae</td><td>8.68172</td></tr><tr><td>mse</td><td>118.54803</td></tr><tr><td>val_loss</td><td>165.0312</td></tr><tr><td>val_mae</td><td>10.44685</td></tr><tr><td>val_mse</td><td>165.0312</td></tr><tr><td>_step</td><td>57</td></tr><tr><td>_runtime</td><td>10482</td></tr><tr><td>_timestamp</td><td>1616943213</td></tr><tr><td>best_val_loss</td><td>161.38457</td></tr><tr><td>best_epoch</td><td>52</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▅▂▅▅▃▄▅▂▂▂▁▂▂▂▂▃▂▁▁▃▃▃▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>▄▆▃▆▅▄▆▆▃▂▂▂▃▄▃▂▄▂▂▁▄▄▄▁▂▁▂▂█▂▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>val_mse</td><td>▄▅▂▅▅▃▄▅▂▂▂▁▂▂▂▂▃▂▁▁▃▃▃▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong>: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/2dzgn0j8\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/2dzgn0j8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1-D: Multi in - multi-out decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training combinations that will now be evaluated: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.23 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/81chjxv7\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/81chjxv7</a><br/>\n",
       "                Run data is saved locally in <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_185850-81chjxv7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'patience': 30, 'epochs': 300, 'lr': 0.01, 'seed': 19951008, 'l_reg': 0, 'log_interval': 1, 'model_name': 'cnn_resnet_1d', 'feature_norm': 'sub_mean_dataloader', 'y_strategy': '', 'dropout': True, 'dataset': 'age', 'embedding': 'mfcc_kaldi', 'folder_fn': 'mfcc/age/', 'mfcc_shape': (200, 30), 'data_augmentation': True, 'selective_data_aug': False, 'kernel_initializer': 'glorot_normal', 'loss': 'mse_plus_cross', 'random_pick_mfcc': True, 'generator on both train and test': True, 'timestamp': '20210328-185850', 'shuffle_temporal': None, 'block_list': [1, 1, 1], 'lr_plateau': True, 'lr_plateau_factor': 0.1, 'lr_plateau_patience': 20, 'relu_type': 'relu', 'batch_norm': True, 'global_average': True, 'reduce_mel': False, 'n_categories': 8, 'multi_output': True, 'sampling_strategy': None, 'without_initial_batch_norm': True, 'cooldown': 10, 'class_weights': None, 'min_lr': 1e-05, 'include_title_only_obs': True, 'unbalanced': True, 'unbalanced_include_title_only_obs': True, 'decreasing_filters': True, 'filter_n': 30, 'kernel_size': 3, 'pool_size': 2, 'dense_n': 256, 'optimizer': 'adam', '2nd_dense_n': 128, 'strides': 1}\n",
      "Shape before: (10972,)\n",
      "Shape after: (54860,)\n",
      "Loading unbalanced_include_title_only_obs\n",
      "Shape before include_title_only_obs: (54860,)\n",
      "Shape after include_title_only_obs: (92955,)\n",
      "Preprocess strat: sub_mean_dataloader\n",
      "23865048\n",
      "model cnn_resnet_1d\n",
      "Initialize model >>>\n",
      "create_res_net_1d >>>\n",
      "Compile_model >>>\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 200, 30)      2730        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 200, 30)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 200, 30)      120         re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 200, 30)      2730        batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 200, 30)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 200, 30)      120         re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 200, 30)      2730        batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 200, 30)      120         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 200, 30)      0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 200, 30)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 200, 30)      120         re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 100, 15)      1365        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 100, 15)      0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 100, 15)      60          re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 100, 15)      690         batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 100, 15)      60          conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 100, 15)      0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 100, 15)      60          re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 50, 15)       0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 50, 7)        322         max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 50, 7)        0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 50, 7)        28          re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 50, 7)        154         batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 50, 7)        28          conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 50, 7)        0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 50, 7)        28          re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 7)            0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7)            0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 7)            0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          2048        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 256)          1024        re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 128)          512         re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 8)            1032        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 49,106\n",
      "Trainable params: 47,966\n",
      "Non-trainable params: 1,140\n",
      "__________________________________________________________________________________________________\n",
      "create_res_net_1d <<<\n",
      "Initialize model <<<\n",
      "multioutput_y_preparation >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khaled/miniconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label encoder output: (92955,)\n",
      "Test label encoder output: (958,)\n",
      "Train (92955,) Test (958, 200, 30) Resnet mode None\n",
      "Epoch 1/300\n",
      "727/727 [==============================] - 186s 237ms/step - loss: 77.2242 - regression_loss: 556.4829 - classifier_loss: 2.1576 - regression_mae: 18.4482 - classifier_accuracy: 0.2114 - val_loss: 38.0260 - val_regression_loss: 189.3863 - val_classifier_loss: 1.9087 - val_regression_mae: 11.1988 - val_classifier_accuracy: 0.2390\n",
      "23922136\n",
      "Epoch 2/300\n",
      "727/727 [==============================] - 166s 229ms/step - loss: 36.0732 - regression_loss: 190.7292 - classifier_loss: 1.7000 - regression_mae: 11.2883 - classifier_accuracy: 0.3372 - val_loss: 35.4166 - val_regression_loss: 178.5920 - val_classifier_loss: 1.7557 - val_regression_mae: 11.1118 - val_classifier_accuracy: 0.2891 regression_loss: 192.7761 - c - ETA: 1:03 - loss: 36.3323 - regression_loss: 192.4515 - classifier_loss: 1.7087 - regression_mae: 11.3430 - classifier_accuracy: 0.33 - ETA: 1:03 - loss: 36.3312 - regression_loss: 192 - ETA: 46s - loss: 36.2545 - regression_loss: 191.9392 - classifier_loss - ETA: 32s - loss: 36.1918 - regression_loss: 191.5183 - class - ETA: 15s - loss: 36.1282 - regression_loss: 191.0956 - classifier_loss: 1.7019 - regression_mae: 11.3001 - ETA: 9s - loss: 36.1059 - regression_loss: 190.94\n",
      "23922196\n",
      "Epoch 3/300\n",
      "727/727 [==============================] - 176s 242ms/step - loss: 34.6450 - regression_loss: 180.4298 - classifier_loss: 1.6602 - regression_mae: 10.9273 - classifier_accuracy: 0.3504 - val_loss: 34.5818 - val_regression_loss: 173.7009 - val_classifier_loss: 1.7212 - val_regression_mae: 10.4103 - val_classifier_accuracy: 0.3288\n",
      "23922220\n",
      "Epoch 4/300\n",
      "727/727 [==============================] - 198s 272ms/step - loss: 33.8367 - regression_loss: 174.0708 - classifier_loss: 1.6430 - regression_mae: 10.6974 - classifier_accuracy: 0.3590 - val_loss: 35.9963 - val_regression_loss: 182.5029 - val_classifier_loss: 1.7746 - val_regression_mae: 11.3881 - val_classifier_accuracy: 0.2797\n",
      "23922220\n",
      "Epoch 5/300\n",
      "727/727 [==============================] - 213s 293ms/step - loss: 33.4155 - regression_loss: 170.1275 - classifier_loss: 1.6403 - regression_mae: 10.5524 - classifier_accuracy: 0.3617 - val_loss: 33.8184 - val_regression_loss: 167.5022 - val_classifier_loss: 1.7068 - val_regression_mae: 10.5228 - val_classifier_accuracy: 0.3372\n",
      "23922220\n",
      "Epoch 6/300\n",
      "727/727 [==============================] - 214s 294ms/step - loss: 32.8598 - regression_loss: 165.7975 - classifier_loss: 1.6280 - regression_mae: 10.4079 - classifier_accuracy: 0.3702 - val_loss: 37.3796 - val_regression_loss: 193.4891 - val_classifier_loss: 1.8031 - val_regression_mae: 10.8414 - val_classifier_accuracy: 0.3257\n",
      "23922220\n",
      "Epoch 7/300\n",
      "727/727 [==============================] - 213s 293ms/step - loss: 32.5640 - regression_loss: 162.9234 - classifier_loss: 1.6272 - regression_mae: 10.3076 - classifier_accuracy: 0.3681 - val_loss: 35.3063 - val_regression_loss: 182.8583 - val_classifier_loss: 1.7020 - val_regression_mae: 10.4408 - val_classifier_accuracy: 0.3445\n",
      "23922224\n",
      "Epoch 8/300\n",
      "727/727 [==============================] - 211s 291ms/step - loss: 32.1326 - regression_loss: 160.2556 - classifier_loss: 1.6107 - regression_mae: 10.2094 - classifier_accuracy: 0.3788 - val_loss: 34.6979 - val_regression_loss: 170.7970 - val_classifier_loss: 1.7618 - val_regression_mae: 10.3045 - val_classifier_accuracy: 0.3309\n",
      "23922236\n",
      "Epoch 9/300\n",
      "727/727 [==============================] - 212s 292ms/step - loss: 31.8670 - regression_loss: 158.4630 - classifier_loss: 1.6021 - regression_mae: 10.1244 - classifier_accuracy: 0.3803 - val_loss: 34.4348 - val_regression_loss: 170.9151 - val_classifier_loss: 1.7343 - val_regression_mae: 10.6335 - val_classifier_accuracy: 0.3309\n",
      "23922236\n",
      "Epoch 10/300\n",
      "727/727 [==============================] - 211s 290ms/step - loss: 31.3694 - regression_loss: 153.7204 - classifier_loss: 1.5997 - regression_mae: 9.9939 - classifier_accuracy: 0.3807 - val_loss: 32.9517 - val_regression_loss: 161.4043 - val_classifier_loss: 1.6811 - val_regression_mae: 10.2652 - val_classifier_accuracy: 0.3434\n",
      "23922236\n",
      "Epoch 11/300\n",
      "727/727 [==============================] - 173s 238ms/step - loss: 31.0767 - regression_loss: 151.6365 - classifier_loss: 1.5913 - regression_mae: 9.9060 - classifier_accuracy: 0.3893 - val_loss: 35.4307 - val_regression_loss: 178.9309 - val_classifier_loss: 1.7538 - val_regression_mae: 10.8608 - val_classifier_accuracy: 0.3215\n",
      "23922236\n",
      "Epoch 12/300\n",
      "727/727 [==============================] - 179s 246ms/step - loss: 30.8705 - regression_loss: 150.0444 - classifier_loss: 1.5866 - regression_mae: 9.8644 - classifier_accuracy: 0.3887 - val_loss: 32.9842 - val_regression_loss: 160.4920 - val_classifier_loss: 1.6935 - val_regression_mae: 9.9860 - val_classifier_accuracy: 0.3507\n",
      "23922236\n",
      "Epoch 13/300\n",
      "727/727 [==============================] - 195s 268ms/step - loss: 30.3257 - regression_loss: 145.8329 - classifier_loss: 1.5742 - regression_mae: 9.7245 - classifier_accuracy: 0.3933 - val_loss: 34.5677 - val_regression_loss: 169.2335 - val_classifier_loss: 1.7644 - val_regression_mae: 10.6483 - val_classifier_accuracy: 0.3142\n",
      "23922236\n",
      "Epoch 14/300\n",
      "727/727 [==============================] - 194s 267ms/step - loss: 30.4716 - regression_loss: 147.2274 - classifier_loss: 1.5749 - regression_mae: 9.7446 - classifier_accuracy: 0.3956 - val_loss: 35.0011 - val_regression_loss: 173.6775 - val_classifier_loss: 1.7633 - val_regression_mae: 10.6273 - val_classifier_accuracy: 0.3225\n",
      "23922236\n",
      "Epoch 15/300\n",
      "727/727 [==============================] - 205s 282ms/step - loss: 30.1982 - regression_loss: 145.1836 - classifier_loss: 1.5680 - regression_mae: 9.6517 - classifier_accuracy: 0.3995 - val_loss: 36.2333 - val_regression_loss: 178.5713 - val_classifier_loss: 1.8376 - val_regression_mae: 11.1028 - val_classifier_accuracy: 0.2985\n",
      "23922236\n",
      "Epoch 16/300\n",
      "727/727 [==============================] - 210s 289ms/step - loss: 29.8810 - regression_loss: 142.3027 - classifier_loss: 1.5651 - regression_mae: 9.5726 - classifier_accuracy: 0.3966 - val_loss: 37.0157 - val_regression_loss: 188.8624 - val_classifier_loss: 1.8129 - val_regression_mae: 11.2985 - val_classifier_accuracy: 0.3225\n",
      "23922236\n",
      "Epoch 17/300\n",
      "727/727 [==============================] - 204s 281ms/step - loss: 29.7065 - regression_loss: 140.8009 - classifier_loss: 1.5626 - regression_mae: 9.5213 - classifier_accuracy: 0.3974 - val_loss: 44.4436 - val_regression_loss: 242.1682 - val_classifier_loss: 2.0227 - val_regression_mae: 12.8106 - val_classifier_accuracy: 0.2777\n",
      "23922236\n",
      "Epoch 18/300\n",
      "727/727 [==============================] - 215s 295ms/step - loss: 29.5334 - regression_loss: 139.8632 - classifier_loss: 1.5547 - regression_mae: 9.4846 - classifier_accuracy: 0.4021 - val_loss: 38.4680 - val_regression_loss: 191.7495 - val_classifier_loss: 1.9293 - val_regression_mae: 11.8122 - val_classifier_accuracy: 0.2589\n",
      "23922236\n",
      "Epoch 19/300\n",
      "727/727 [==============================] - 211s 289ms/step - loss: 29.4746 - regression_loss: 139.2472 - classifier_loss: 1.5550 - regression_mae: 9.4621 - classifier_accuracy: 0.4021 - val_loss: 33.6432 - val_regression_loss: 168.1578 - val_classifier_loss: 1.6827 - val_regression_mae: 10.2031 - val_classifier_accuracy: 0.3466\n",
      "23922236\n",
      "Epoch 20/300\n",
      "727/727 [==============================] - 220s 302ms/step - loss: 29.2630 - regression_loss: 137.3975 - classifier_loss: 1.5523 - regression_mae: 9.4028 - classifier_accuracy: 0.4018 - val_loss: 35.1298 - val_regression_loss: 175.0452 - val_classifier_loss: 1.7625 - val_regression_mae: 10.8597 - val_classifier_accuracy: 0.3246\n",
      "23922236\n",
      "Epoch 21/300\n",
      "727/727 [==============================] - 196s 270ms/step - loss: 29.2726 - regression_loss: 137.3973 - classifier_loss: 1.5533 - regression_mae: 9.3874 - classifier_accuracy: 0.4024 - val_loss: 33.3974 - val_regression_loss: 163.0413 - val_classifier_loss: 1.7093 - val_regression_mae: 10.1107 - val_classifier_accuracy: 0.3361\n",
      "23922236\n",
      "Epoch 22/300\n",
      "727/727 [==============================] - 195s 268ms/step - loss: 28.9275 - regression_loss: 134.6430 - classifier_loss: 1.5463 - regression_mae: 9.3117 - classifier_accuracy: 0.4031 - val_loss: 36.8495 - val_regression_loss: 188.1206 - val_classifier_loss: 1.8037 - val_regression_mae: 11.2171 - val_classifier_accuracy: 0.3246\n",
      "23922236\n",
      "Epoch 23/300\n",
      "727/727 [==============================] - 203s 279ms/step - loss: 28.9179 - regression_loss: 134.9346 - classifier_loss: 1.5424 - regression_mae: 9.3189 - classifier_accuracy: 0.4078 - val_loss: 41.0483 - val_regression_loss: 214.3585 - val_classifier_loss: 1.9612 - val_regression_mae: 12.2654 - val_classifier_accuracy: 0.2850\n",
      "23922236\n",
      "Epoch 24/300\n",
      "727/727 [==============================] - 202s 278ms/step - loss: 28.6815 - regression_loss: 133.0815 - classifier_loss: 1.5373 - regression_mae: 9.2244 - classifier_accuracy: 0.4068 - val_loss: 38.4375 - val_regression_loss: 195.3304 - val_classifier_loss: 1.8904 - val_regression_mae: 11.7156 - val_classifier_accuracy: 0.2985\n",
      "23922236\n",
      "Epoch 25/300\n",
      "727/727 [==============================] - 211s 290ms/step - loss: 28.6996 - regression_loss: 133.1822 - classifier_loss: 1.5381 - regression_mae: 9.2562 - classifier_accuracy: 0.4105 - val_loss: 33.8451 - val_regression_loss: 168.8878 - val_classifier_loss: 1.6956 - val_regression_mae: 10.5276 - val_classifier_accuracy: 0.3466\n",
      "23922236\n",
      "Epoch 26/300\n",
      "727/727 [==============================] - 207s 285ms/step - loss: 28.6603 - regression_loss: 132.7513 - classifier_loss: 1.5385 - regression_mae: 9.2259 - classifier_accuracy: 0.4081 - val_loss: 33.8930 - val_regression_loss: 169.4037 - val_classifier_loss: 1.6953 - val_regression_mae: 10.0702 - val_classifier_accuracy: 0.3382\n",
      "23922236\n",
      "Epoch 27/300\n",
      "727/727 [==============================] - 209s 287ms/step - loss: 28.6697 - regression_loss: 132.7511 - classifier_loss: 1.5395 - regression_mae: 9.2096 - classifier_accuracy: 0.4066 - val_loss: 33.1125 - val_regression_loss: 161.2264 - val_classifier_loss: 1.6990 - val_regression_mae: 10.0134 - val_classifier_accuracy: 0.3601\n",
      "23922236\n",
      "Epoch 28/300\n",
      "727/727 [==============================] - 216s 296ms/step - loss: 28.4031 - regression_loss: 130.9362 - classifier_loss: 1.5310 - regression_mae: 9.1346 - classifier_accuracy: 0.4117 - val_loss: 32.8388 - val_regression_loss: 158.4541 - val_classifier_loss: 1.6993 - val_regression_mae: 10.1447 - val_classifier_accuracy: 0.3580\n",
      "23922236\n",
      "Epoch 29/300\n",
      "727/727 [==============================] - 211s 289ms/step - loss: 28.4140 - regression_loss: 130.7203 - classifier_loss: 1.5342 - regression_mae: 9.1835 - classifier_accuracy: 0.4095 - val_loss: 44.6930 - val_regression_loss: 249.8217 - val_classifier_loss: 1.9711 - val_regression_mae: 13.0785 - val_classifier_accuracy: 0.2829\n",
      "23922236\n",
      "Epoch 30/300\n",
      "727/727 [==============================] - 213s 292ms/step - loss: 28.2795 - regression_loss: 129.8259 - classifier_loss: 1.5297 - regression_mae: 9.1356 - classifier_accuracy: 0.4107 - val_loss: 33.2197 - val_regression_loss: 162.2176 - val_classifier_loss: 1.6998 - val_regression_mae: 10.0423 - val_classifier_accuracy: 0.3497\n",
      "23922236\n",
      "Epoch 31/300\n",
      "727/727 [==============================] - 220s 302ms/step - loss: 28.1500 - regression_loss: 129.0400 - classifier_loss: 1.5246 - regression_mae: 9.0975 - classifier_accuracy: 0.4146 - val_loss: 34.0443 - val_regression_loss: 169.1963 - val_classifier_loss: 1.7125 - val_regression_mae: 10.4266 - val_classifier_accuracy: 0.3445\n",
      "23922236\n",
      "Epoch 32/300\n",
      "727/727 [==============================] - 217s 298ms/step - loss: 27.9196 - regression_loss: 127.0573 - classifier_loss: 1.5214 - regression_mae: 9.0112 - classifier_accuracy: 0.4153 - val_loss: 35.4108 - val_regression_loss: 176.2397 - val_classifier_loss: 1.7787 - val_regression_mae: 10.8056 - val_classifier_accuracy: 0.3278\n",
      "23922236\n",
      "Epoch 33/300\n",
      "727/727 [==============================] - 218s 300ms/step - loss: 27.7524 - regression_loss: 126.5693 - classifier_loss: 1.5095 - regression_mae: 9.0117 - classifier_accuracy: 0.4197 - val_loss: 33.4077 - val_regression_loss: 162.9117 - val_classifier_loss: 1.7117 - val_regression_mae: 10.3119 - val_classifier_accuracy: 0.3507\n",
      "23922236\n",
      "Epoch 34/300\n",
      "727/727 [==============================] - 211s 290ms/step - loss: 27.3182 - regression_loss: 123.6903 - classifier_loss: 1.4949 - regression_mae: 8.8823 - classifier_accuracy: 0.4238 - val_loss: 33.2967 - val_regression_loss: 162.3820 - val_classifier_loss: 1.7058 - val_regression_mae: 10.2466 - val_classifier_accuracy: 0.3570\n",
      "23922236\n",
      "Epoch 35/300\n",
      "727/727 [==============================] - 213s 293ms/step - loss: 27.0869 - regression_loss: 121.9193 - classifier_loss: 1.4895 - regression_mae: 8.8136 - classifier_accuracy: 0.4263 - val_loss: 33.6879 - val_regression_loss: 164.7787 - val_classifier_loss: 1.7210 - val_regression_mae: 10.3933 - val_classifier_accuracy: 0.35077.0592 - regression_lo\n",
      "23922236\n",
      "Epoch 36/300\n",
      "727/727 [==============================] - 206s 284ms/step - loss: 27.2557 - regression_loss: 123.1798 - classifier_loss: 1.4938 - regression_mae: 8.8404 - classifier_accuracy: 0.4265 - val_loss: 32.9960 - val_regression_loss: 160.0815 - val_classifier_loss: 1.6988 - val_regression_mae: 10.1762 - val_classifier_accuracy: 0.3539\n",
      "23922236\n",
      "Epoch 37/300\n",
      "727/727 [==============================] - 208s 286ms/step - loss: 27.1923 - regression_loss: 122.9674 - classifier_loss: 1.4896 - regression_mae: 8.8602 - classifier_accuracy: 0.4265 - val_loss: 33.9156 - val_regression_loss: 166.6554 - val_classifier_loss: 1.7250 - val_regression_mae: 10.5019 - val_classifier_accuracy: 0.3497\n",
      "23922236\n",
      "Epoch 38/300\n",
      "727/727 [==============================] - 211s 291ms/step - loss: 27.0790 - regression_loss: 121.6885 - classifier_loss: 1.4910 - regression_mae: 8.7985 - classifier_accuracy: 0.4245 - val_loss: 33.3497 - val_regression_loss: 162.7221 - val_classifier_loss: 1.7077 - val_regression_mae: 10.3079 - val_classifier_accuracy: 0.3497\n",
      "23922236\n",
      "Epoch 39/300\n",
      "727/727 [==============================] - 214s 294ms/step - loss: 27.1342 - regression_loss: 122.5729 - classifier_loss: 1.4877 - regression_mae: 8.8248 - classifier_accuracy: 0.4249 - val_loss: 33.2729 - val_regression_loss: 161.5091 - val_classifier_loss: 1.7122 - val_regression_mae: 10.2482 - val_classifier_accuracy: 0.3497\n",
      "23922236\n",
      "Epoch 40/300\n",
      "727/727 [==============================] - 208s 286ms/step - loss: 27.2087 - regression_loss: 122.8839 - classifier_loss: 1.4920 - regression_mae: 8.8326 - classifier_accuracy: 0.4270 - val_loss: 33.8962 - val_regression_loss: 166.3895 - val_classifier_loss: 1.7257 - val_regression_mae: 10.4257 - val_classifier_accuracy: 0.3528\n",
      "23922236\n",
      "Epoch 41/300\n",
      "727/727 [==============================] - 219s 300ms/step - loss: 27.0264 - regression_loss: 121.2307 - classifier_loss: 1.4903 - regression_mae: 8.7914 - classifier_accuracy: 0.4273 - val_loss: 33.7855 - val_regression_loss: 165.9456 - val_classifier_loss: 1.7191 - val_regression_mae: 10.3810 - val_classifier_accuracy: 0.3518\n",
      "23922236\n",
      "Epoch 42/300\n",
      "727/727 [==============================] - 214s 295ms/step - loss: 26.9097 - regression_loss: 120.7967 - classifier_loss: 1.4830 - regression_mae: 8.7540 - classifier_accuracy: 0.4291 - val_loss: 34.1149 - val_regression_loss: 168.0189 - val_classifier_loss: 1.7313 - val_regression_mae: 10.5087 - val_classifier_accuracy: 0.3476\n",
      "23922236\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "norm_strat_to_evaluate = ['sub_mean_dataloader']\n",
    "y_strategy = ['']\n",
    "l_reg = [0.0]\n",
    "filter_n = [30]\n",
    "kernel_size = [3]\n",
    "pool_size = [(2)]\n",
    "dense_n = [256]\n",
    "batch_size = [128]\n",
    "lr = [0.01]\n",
    "optimizer = ['adam']\n",
    "second_dense_n = [128]\n",
    "data_augmentation = [True]\n",
    "selective_data_aug = [False]\n",
    "loss = ['mse_plus_cross']\n",
    "block_list = [[1, 1, 1]]\n",
    "global_avg = [True]\n",
    "train_combinations = list(itertools.product(['cnn_resnet_1d'],\n",
    "                                            norm_strat_to_evaluate,\n",
    "                                            y_strategy,\n",
    "                                            l_reg,\n",
    "                                            filter_n,\n",
    "                                            kernel_size,\n",
    "                                            pool_size,\n",
    "                                            dense_n,\n",
    "                                            batch_size,\n",
    "                                            lr,\n",
    "                                            optimizer,\n",
    "                                            second_dense_n,\n",
    "                                            data_augmentation,\n",
    "                                            selective_data_aug,\n",
    "                                            loss,\n",
    "                                            block_list,\n",
    "                                            global_avg\n",
    "                                            ))\n",
    "print(\"Number of training combinations that will now be evaluated:\", len(train_combinations))\n",
    "model = None\n",
    "for model, strategy, y_strat, l_reg_value, n_filt, n_kern, n_pool, n_dense, n_batch, lr, optim, neuron_2nd_dense, data_aug, sel_data_aug, loss_type, n_blocks, g_avg in train_combinations:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    config = {\n",
    "        'batch_size': n_batch,\n",
    "        'patience': 30,\n",
    "        'epochs': 300,\n",
    "        'lr': lr,\n",
    "        'seed': my_seed,\n",
    "        'l_reg': 0,\n",
    "        'log_interval': 1,\n",
    "        'model_name': model,\n",
    "        'feature_norm': strategy,\n",
    "        'y_strategy': y_strat,\n",
    "        'dropout': True,\n",
    "        'dataset': 'age',\n",
    "        'embedding': 'mfcc_kaldi',\n",
    "        'folder_fn': 'mfcc/age/',\n",
    "        'mfcc_shape': (200, X[0].shape[1]),\n",
    "        'data_augmentation': data_aug,\n",
    "        'selective_data_aug': sel_data_aug,\n",
    "        'kernel_initializer': 'glorot_normal',\n",
    "        'loss': loss_type,\n",
    "        'random_pick_mfcc': True,\n",
    "        'generator on both train and test': True,\n",
    "        'timestamp': timestr,\n",
    "        'shuffle_temporal': None,\n",
    "        'block_list': n_blocks,\n",
    "        'lr_plateau': True,\n",
    "        'lr_plateau_factor': 0.1,\n",
    "        'lr_plateau_patience': 20,\n",
    "        'relu_type': 'relu',\n",
    "        'batch_norm': True,\n",
    "        'global_average': g_avg,\n",
    "        'reduce_mel': False,\n",
    "        'n_categories': 8,\n",
    "        'multi_output': True,\n",
    "        'sampling_strategy': None,\n",
    "        'without_initial_batch_norm': True,\n",
    "        'cooldown': 10,\n",
    "        'class_weights': None,\n",
    "        'min_lr': 0.00001,\n",
    "        'include_title_only_obs': True,\n",
    "        'unbalanced': True,\n",
    "        'unbalanced_include_title_only_obs': True,\n",
    "        'decreasing_filters': True\n",
    "\n",
    "    }\n",
    "    config['filter_n'] = n_filt\n",
    "    config['kernel_size'] = n_kern\n",
    "    config['pool_size'] = n_pool\n",
    "    config['dense_n'] = n_dense\n",
    "    config['optimizer'] = optim\n",
    "    config['2nd_dense_n'] = neuron_2nd_dense\n",
    "    config['strides'] = 1\n",
    "    wandb.init(\n",
    "        project='voxceleb_enrichment',\n",
    "        name='_'.join([model, config['embedding'], strategy]),\n",
    "        config=config\n",
    "    )\n",
    "    print(config)\n",
    "    model = train_holdout(X, y, X_test, y_test, X_aug, y_aug, strategy, config['model_name'], config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-20210328-185850/assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9688<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_185850-81chjxv7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/khaled/age_gender_recognition/asvtorch_modified/asvtorch/notebooks/wandb/run-20210328_185850-81chjxv7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>41</td></tr><tr><td>loss</td><td>26.98375</td></tr><tr><td>regression_loss</td><td>121.17906</td></tr><tr><td>classifier_loss</td><td>1.48658</td></tr><tr><td>regression_mae</td><td>8.76789</td></tr><tr><td>classifier_accuracy</td><td>0.42725</td></tr><tr><td>val_loss</td><td>34.11488</td></tr><tr><td>val_regression_loss</td><td>168.01892</td></tr><tr><td>val_classifier_loss</td><td>1.7313</td></tr><tr><td>val_regression_mae</td><td>10.50871</td></tr><tr><td>val_classifier_accuracy</td><td>0.3476</td></tr><tr><td>_step</td><td>41</td></tr><tr><td>_runtime</td><td>8667</td></tr><tr><td>_timestamp</td><td>1616955800</td></tr><tr><td>best_val_loss</td><td>32.83878</td></tr><tr><td>best_epoch</td><td>27</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>█▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>regression_loss</td><td>█▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>classifier_loss</td><td>█▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>regression_mae</td><td>█▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>classifier_accuracy</td><td>▁▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>val_loss</td><td>▄▃▂▃▂▄▂▂▂▁▃▁▂▂▃▃█▄▁▂▃▆▄▂▂▁▁█▁▂▃▁▁▂▁▂▁▁▂▂</td></tr><tr><td>val_regression_loss</td><td>▃▃▂▃▂▄▃▂▂▁▃▁▂▂▃▃▇▄▂▂▃▅▄▂▂▁▁█▁▂▂▁▁▁▁▂▁▁▂▂</td></tr><tr><td>val_classifier_loss</td><td>▆▃▂▃▂▃▁▃▂▁▂▁▃▃▄▄█▆▁▃▄▇▅▁▁▁▁▇▁▂▃▂▂▂▁▂▂▂▂▂</td></tr><tr><td>val_regression_mae</td><td>▄▄▂▄▂▃▂▂▂▂▃▁▂▂▄▄▇▅▁▃▄▆▅▂▁▁▁█▁▂▃▂▂▂▁▂▂▂▂▂</td></tr><tr><td>val_classifier_accuracy</td><td>▁▄▆▃▇▆▇▆▆▇▆▇▅▆▄▆▃▂▇▆▆▄▄▇▇██▄▇▇▆▇█▇█▇▇▇█▇</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn_resnet_1d_mfcc_kaldi_sub_mean_dataloader</strong>: <a href=\"https://wandb.ai/hechmik/voxceleb_enrichment/runs/81chjxv7\" target=\"_blank\">https://wandb.ai/hechmik/voxceleb_enrichment/runs/81chjxv7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"model-{}\".format(config['timestamp']))\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO Data augm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models\n",
    "## CNN 1-D : Single input - single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model-20210328-102247/', compile='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 30)      2730        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 200, 30)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200, 30)      120         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 30)      2730        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 200, 30)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 200, 30)      120         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 200, 30)      2730        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200, 30)      120         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 30)      0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 200, 30)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 200, 30)      120         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 30)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 60)      5460        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 100, 60)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 60)      240         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 60)      10860       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 60)      240         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 100, 60)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 60)      240         re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 50, 60)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 120)      21720       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 50, 120)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 50, 120)      480         re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 120)      43320       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 120)      480         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 50, 120)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 120)      480         re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 120)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 120)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 120)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          30976       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128)          512         re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 157,727\n",
      "Trainable params: 155,639\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 359 ms, total: 2.19 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('/media/hdd1/khaled/npz_files/final_version/test_data.npz', allow_pickle=True)\n",
    "\n",
    "vectors = []\n",
    "for x in list(data.keys()):\n",
    "    vectors.append(data[x])\n",
    "X_test, y_test, X_spk_video_labels_test = vectors\n",
    "data.close()\n",
    "data = None\n",
    "vectors = None\n",
    "del data, vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_correct_recordings_index >>>\n",
      "1\n",
      "get_correct_recordings_index <<<\n"
     ]
    }
   ],
   "source": [
    "X_test_mel = empty(X_test.shape, dtype='object')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_mel[i] = scipy.fftpack.idct(X_test[i])\n",
    "X_spk_labels_test = [''.join(x.split('-')[1:]) for x in X_spk_video_labels_test]\n",
    "test_ids_balanced = get_correct_recordings_index(X_spk_labels_test)\n",
    "len(test_ids_balanced)\n",
    "X_test = X_test[test_ids_balanced]\n",
    "y_test = y_test[test_ids_balanced]\n",
    "X_test_mel = X_test_mel[test_ids_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [08:03<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_avg = []\n",
    "for i, test_track in enumerate(tqdm(X_test)):\n",
    "    n_slice_to_compute = test_track.shape[0] - 200\n",
    "    current_track_pred = []\n",
    "    for idx in range(0, n_slice_to_compute, 100):        \n",
    "        sliced_track = test_track[idx:idx+200,:]\n",
    "        #print(sliced_track.shape)\n",
    "        sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "        #print(sliced_track.shape)\n",
    "        slice_pred = model.predict(sliced_track.reshape(1, 200, 30))\n",
    "        current_track_pred.append(slice_pred)\n",
    "    # Last prediction:\n",
    "    sliced_track = test_track[-200:,:]\n",
    "    sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "    #print(sliced_track.shape)\n",
    "    slice_pred = model.predict(sliced_track.reshape(1, 200, 30))\n",
    "    current_track_pred.append(slice_pred)\n",
    "    y_pred_avg.append(np.mean(current_track_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "np.savetxt(\"y_pred-cnn_single_single.txt\", y_pred_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.442898750305176"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.array(y_pred_avg) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [00:00<00:00, 211871.51it/s]\n"
     ]
    }
   ],
   "source": [
    "n_steps = []\n",
    "for i, test_track in enumerate(tqdm(X_test)):\n",
    "    n_slice_to_compute = test_track.shape[0] - 200\n",
    "    n_steps.append(n_slice_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482316"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503.4613778705637"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517.7237759810298"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1D - Multiout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model-20210328-002928/', compile='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [08:08<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_avg = []\n",
    "for i, test_track in enumerate(tqdm(X_test)):\n",
    "    n_slice_to_compute = test_track.shape[0] - 200\n",
    "    current_track_pred = []\n",
    "    for idx in range(0, n_slice_to_compute, 100):        \n",
    "        sliced_track = test_track[idx:idx+200,:]\n",
    "        #print(sliced_track.shape)\n",
    "        sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "        #print(sliced_track.shape)\n",
    "        slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "        current_track_pred.append(slice_pred)\n",
    "    # Last prediction:\n",
    "    sliced_track = test_track[-200:,:]\n",
    "    sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "    #print(sliced_track.shape)\n",
    "    slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "    current_track_pred.append(slice_pred)\n",
    "    y_pred_avg.append(np.mean(current_track_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.510689193868936"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.array(y_pred_avg) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [08:48<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 25s, sys: 10.5 s, total: 8min 35s\n",
      "Wall time: 8min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = keras.models.load_model('model-20210328-223050/', compile='false')\n",
    "y_pred_avg = []\n",
    "for i, test_track in enumerate(tqdm(X_test)):\n",
    "    n_slice_to_compute = test_track.shape[0] - 200\n",
    "    current_track_pred = []\n",
    "    for idx in range(0, n_slice_to_compute, 100):        \n",
    "        sliced_track = test_track[idx:idx+200,:]\n",
    "        #print(sliced_track.shape)\n",
    "        sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "        #print(sliced_track.shape)\n",
    "        slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "        current_track_pred.append(slice_pred)\n",
    "    # Last prediction:\n",
    "    sliced_track = test_track[-200:,:]\n",
    "    sliced_track = sliced_track - np.mean(sliced_track,axis=0)\n",
    "    #print(sliced_track.shape)\n",
    "    slice_pred = model.predict(sliced_track.reshape(1, 200, 30))[0]\n",
    "    current_track_pred.append(slice_pred)\n",
    "    y_pred_avg.append(np.mean(current_track_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.325782783842783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(np.array(y_pred_avg) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
